{
  "hash": "08a27bd6f50665de52f019af76c51ac4",
  "result": {
    "engine": "jupyter",
    "markdown": "---\ntitle: \"Web Scraping and Textual Analytics\"\nformat: html\n---\n\n### Learning Objectives of the Chapter {.unnumbered}\n\n::: {style=\"text-align: justify\"}\nAt the End of the Chapter, Students should be Able to -\n\n-   Gain an Understanding about Web Scraping and Its Importance\n\n-   Understand the Website Structures for Web Scraping\n\n-   Use Python Modules to Scrape Websites\n\n-   Scrape `EDGAR` Website to Extract Quantitative and Qualitative Data of Different Companies\n:::\n\n## What is Web Scraping?\n\n::: {style=\"text-align: justify\"}\n     Web scraping refers to the techniques of accessing websites and collecting information from them. Having web scraping knowledge is important nowadays because a vast amount of data is available on websites and in many occasions we need to access, collect, and analyze those data. Web scraping is also called \"web harvesting\" or \"web data extraction\".\n\n     Web scraping is employed in different kinds of practical applications. For example, companies scrape websites of their competitors to keep track of their pricing, which can help companies to form a competitive pricing strategy. Moreover, marketers and analysts scrape different social media platforms to analyze public sentiment about their products, brands, or events, which help them to gauge public opinions and ultimately tailor their products or services to meet or exceed customers' expectations.\n:::\n\n## Legal and Ethical Consideration of Web Scraping\n\n::: {style=\"text-align: justify\"}\n     As good citizens on the internet, it is incumbent on us to respect the policies of the websites we plan to scrape. Therefore, before we decide to scrape a website, we must take into consideration the legal and ethical aspects of scraping.\n:::\n\n### Legal Framework of Web Scraping\n\n::: {style=\"text-align: justify\"}\n     Before scraping a website, we must evaluate the following legal considerations -\n\n1.  **Terms of Service**: Please check the terms of service of the website because some sites explicitly prohibit scraping and violating terms of service might result in legal action.\n\n2.  **Copyright Law**: In most cases, data published online is protected by copyright. As such, it is important to know beforehand what you can legally collect from the website by scraping and how you can use the scraped data.\n\n3.  **Computer Fraud and Abuse Act (CFAA)**: In the US, the Computer Fraud and Abuse Act (CFAA) was enacted in 1986. The CFAA prohibits intentionally accessing a computer without authorization or in excess of authorization. You might violate CFAA if a website has taken steps to block scraping and you circumvent those measures.\n\n4.  **Data Protection Law**: Beacause of different kinds of data protection law such as General Data Protection Regulation (GDPR) in Europe or similar law in other jurisdictions, it has become very critical to deal with personal data. If you scrape personal data, you must comply with such laws, which typically include requirements for consent, data minimization, and secure handling of the data.\n:::\n\n### Ethical Considerations of Web Scraping\n\n::: {style=\"text-align: justify\"}\n     In addition to legal considerations, you should also behave ethically when you try to scrape a website. Ethical considerations though aligns with legal considerations, they extend to the idea of good citizenship on the web. Some important ethical considerations during webscraping include -\n\n1.  Web scraping might be equivalent to Distriubted of Denial of Service (DDOS) attack if too many requests are sent to the targeted websites, thus disrupting the regular functioning of the website. Therefore, while web scraping, we should scrape in such a way so that it does not disrupt the usage of the website by other legitimate users. Further, you should not try to scrape a website if it prohibits web scraping. Some websites have `robots.txt` file, which defines what can be scraped from the website. So please invesitage a website well before you decide to scrape it.\n\n2.  How the scraped data will be used is an important considerations even if the data are publicly available. Using the web scraped data in a way that is detrimental to individual or businesses is unethical. Further, you should also consider the ramifications of publishing or sharing the scraped data.\n:::\n\n## Understanding HTML and CSS Selectors\n\n::: {style=\"text-align: justify\"}\n     Websites are usually created by using HTML - HyperText Markup Language, which describes the structure of a web page and includes cues for the apperance of a website. Therefore, having some knowledge on HTML will help you to scrape a website. HTML document uses different kinds of tags to identify or refer to different elements. A typical HTML document has following elements -\n\n`<!DOCTYPE>` : Defines the document type\n\n`<html>` : Defines the HTML document\n\n`<head>` : Contains metadata or information for the document\n\n`<body>` : Defines the document body such as text, images, and other media\n\n     More about HTML tags can be found [here](https://www.w3schools.com/tags/ref_byfunc.asp). Here is an example of a basic HTML structure -\n\n::: {#dd0b1cab .cell execution_count=1}\n``` {.python .cell-code}\n<html><head><title>The Dormouse's story</title></head>\n<body>\n<p class=\"title\"><b>The Dormouse's story</b></p>\n<p class=\"story\">Once upon a time there were three little sisters; and their names were\n<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\nand they lived at the bottom of a well.</p>\n</body></html>\n```\n:::\n\n\n     In addition to HTML tags, CSS (Cascading Style Sheets) selectors are used to style different elements in the website. In web scraping, we use CSS selectors to identify the data we want to extract. There are different types of CSS selectors:\n\n1.  **Element Selector**: Selects all elements of a specific type. For example, `p` selects all `<p>` elements.\n\n2.  **ID Selector**: Selects a single element with a specific id. The ID selector is defined with a hash (`#`). For example, `#navbar` selects the element with `id=\"navbar\"`.\n\n3.  **Class Selector**: Selects all elements with a specific class. The class selector is defined with a dot (`.`). For example, `.menu-item` selects all elements with `class=\"menu-item\"`.\n\n4.  **Attribute Selector**: Selects elements with a specific attribute or attribute value. For example, `[href]` selects all elements with an `href` attribute.\n\n     Below is an example of CSS selectors -\n\n::: {#4d3be951 .cell execution_count=2}\n``` {.python .cell-code}\n<!DOCTYPE html>\n<html>\n<head>\n    <style>\n        #header {\n            background-color: #f2f2f2;\n        }\n        .highlight {\n            font-weight: bold;\n        }\n        a[href^=\"https\"] {\n            color: green;\n        }\n    </style>\n</head>\n<body>\n    <div id=\"header\">This is the header</div>\n    <p class=\"highlight\">This paragraph is highlighted.</p>\n    <a href=\"https://example.com\">This link is green because it uses HTTPS.</a>\n</body>\n</html>\n```\n:::\n\n\n     In the above code, `#header` selects the `<div>` with the ID of \"header,\" `.highlight` selects any element with the \"highlight\" class, and `a[href^=\"https\"]` selects anchor tags (`<a>`) whose `href` attribute value begins with \"https\". Understanding how to use these CSS selectors are very important while web scraping websites.\n:::\n\n## An Overview of Beautiful Soup\n\n::: {style=\"text-align: justify\"}\n     `Beautifulsoup` is a python module that is widely used to scrape and parse websites. `Beautifulsoup` has many useful functions that can be easily used to extract data from HTML. @fig-beautifulsoupprocess shows the basic work process `Beautifulsoup` uses. It is clear from @fig-beautifulsoupprocess that using `Beautifulsoup`, we can extract data by finding HTML tag names, by CSS class names, and so on.\n\n![Beautiful Soup Process](images/beautiful_soup_process.jpg){#fig-beautifulsoupprocess}\n\n     The following python code can be run to install and import `Beautifulsoup` module.\n\n::: {#d14cac29 .cell execution_count=3}\n``` {.python .cell-code}\n# installing beautifulsoup \npip install beautifulsoup4\n\n# importing beautifulsoup\nfrom bs4 import BeautifulSoup\n```\n:::\n\n\n     When we use `BeautifulSoup` to scrape a website, one of the most critical tasks is to identify the tags or CSS selectors from which we want to extract text or data. These targets are called Document Object Model (DOM). The DOM is a programming interface for web documents. Visualize HTML code of a webpage as an upside-down tree. Each HTML element - headings, paragraphs, and links - is a node in the tree. @fig-dom shows a basic tree structure of an HTML page.\n\n![Tree Structure of HTML Page](images/dom.png){#fig-dom}\n:::\n\n### An Example of Web Scraping\n\n::: {style=\"text-align: justify\"}\n     Below we provide a small example of webscraping. We create a webpage called `html`, which includes different tags and CSS selectors.\n\n::: {#1973fae1 .cell execution_count=4}\n``` {.python .cell-code}\n# an HTML file data \n\nhtml = \"\"\"\n<html><head><title>The Dormouse's story</title></head>\n<body>\n<p class=\"title\"><b>The Dormouse's story</b></p>\n<p class=\"story\">Once upon a time there were three little sisters; and their names were\n<a href=\"http://example.com/elsie\" class=\"sister\" id=\"link1\">Elsie</a>,\n<a href=\"http://example.com/lacie\" class=\"sister\" id=\"link2\">Lacie</a> and\n<a href=\"http://example.com/tillie\" class=\"sister\" id=\"link3\">Tillie</a>;\nand they lived at the bottom of a well.</p>\n</body></html>\"\"\"\n```\n:::\n\n\n     Then we import `BeautifulSoup` from beautifulsoup.\n\n::: {#7e8b44e1 .cell execution_count=5}\n``` {.python .cell-code}\n# importing beautiful soup \nfrom bs4 import BeautifulSoup\n```\n:::\n\n\n     Next, we convert the `html` into beautifulsoup object and name it `soup`. In `BeautifulSoup ()`function, we use the built-in parser called `html.parser`. We can also use other parsers such as `lxml` or `html5lib`. Each of these parsers has their own pros and cons. For example, `lxml` is the fastest and `html.parser` does not need extra dependencies.\n\n::: {#d063bab8 .cell execution_count=6}\n``` {.python .cell-code}\n# Converting HTML data into Beautiful Soup Object \nsoup = BeautifulSoup(html, \"html.parser\")\n```\n:::\n\n\n     The `prettify()` function will turn a soup object into a nicely formatted Unicode string, witha a separate line for each tag and each string.\n\n::: {#f41b3027 .cell execution_count=7}\n``` {.python .cell-code}\nsoup.prettify()\n```\n\n::: {.cell-output .cell-output-display execution_count=62}\n```\n'<html>\\n <head>\\n  <title>\\n   The Dormouse\\'s story\\n  </title>\\n </head>\\n <body>\\n  <p class=\"title\">\\n   <b>\\n    The Dormouse\\'s story\\n   </b>\\n  </p>\\n  <p class=\"story\">\\n   Once upon a time there were three little sisters; and their names were\\n   <a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">\\n    Elsie\\n   </a>\\n   ,\\n   <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">\\n    Lacie\\n   </a>\\n   and\\n   <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">\\n    Tillie\\n   </a>\\n   ;\\nand they lived at the bottom of a well.\\n  </p>\\n </body>\\n</html>\\n'\n```\n:::\n:::\n\n\n     We can use `get_text()` function to see the text element of the tags. `text` is a property (attribute) of soup object, which calls `get_text` function.\n\n::: {#7a690461 .cell execution_count=8}\n``` {.python .cell-code}\nsoup.get_text()\n```\n\n::: {.cell-output .cell-output-display execution_count=63}\n```\n\"\\nThe Dormouse's story\\n\\nThe Dormouse's story\\nOnce upon a time there were three little sisters; and their names were\\nElsie,\\nLacie and\\nTillie;\\nand they lived at the bottom of a well.\\n\"\n```\n:::\n:::\n\n\n::: {#c94419ef .cell execution_count=9}\n``` {.python .cell-code}\nsoup.text\n```\n\n::: {.cell-output .cell-output-display execution_count=64}\n```\n\"\\nThe Dormouse's story\\n\\nThe Dormouse's story\\nOnce upon a time there were three little sisters; and their names were\\nElsie,\\nLacie and\\nTillie;\\nand they lived at the bottom of a well.\\n\"\n```\n:::\n:::\n\n\n::: {#41f3c6ef .cell execution_count=10}\n``` {.python .cell-code}\nprint(soup.text)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nThe Dormouse's story\n\nThe Dormouse's story\nOnce upon a time there were three little sisters; and their names were\nElsie,\nLacie and\nTillie;\nand they lived at the bottom of a well.\n\n```\n:::\n:::\n\n\n     To see the title of the document, we run the following codes -\n\n::: {#2b19f7d1 .cell execution_count=11}\n``` {.python .cell-code}\n# Navigating to Specific Tags \nsoup.head.title\n```\n\n::: {.cell-output .cell-output-display execution_count=66}\n```\n<title>The Dormouse's story</title>\n```\n:::\n:::\n\n\n::: {#bf3db3be .cell execution_count=12}\n``` {.python .cell-code}\n# Getting Text from a Specific Tag\nsoup.head.title.text\n```\n\n::: {.cell-output .cell-output-display execution_count=67}\n```\n\"The Dormouse's story\"\n```\n:::\n:::\n\n\n     To see the text, from `a` tag, we run the following code -\n\n::: {#e4d81165 .cell execution_count=13}\n``` {.python .cell-code}\nsoup.body.a.text\n```\n\n::: {.cell-output .cell-output-display execution_count=68}\n```\n'Elsie'\n```\n:::\n:::\n\n\n     To see the text, from `p` tag, we run the following code -\n\n::: {#7fd29a5e .cell execution_count=14}\n``` {.python .cell-code}\nsoup.body.p.text\n```\n\n::: {.cell-output .cell-output-display execution_count=69}\n```\n\"The Dormouse's story\"\n```\n:::\n:::\n\n\n:::\n\n## Searching the Elements of Tags\n\n::: {style=\"text-align: justify\"}\n     The `find_all()` function from beautifulsoup takes an HTML tag as an string argument and returns the list of elements that match the tag. For example, if we want to have all `a` tags in `html` data above, we will run the following code. Please note that there is another similar function called `find()`, which will return the first tag element.\n\n::: {#be95cd55 .cell execution_count=15}\n``` {.python .cell-code}\nsoup.find_all('a')\n```\n\n::: {.cell-output .cell-output-display execution_count=70}\n```\n[<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n <a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a>,\n <a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>]\n```\n:::\n:::\n\n\n::: {#6d54bb0a .cell execution_count=16}\n``` {.python .cell-code}\nsoup.find('a')\n```\n\n::: {.cell-output .cell-output-display execution_count=71}\n```\n<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>\n```\n:::\n:::\n\n\n     We can also search for tags of a specific class as well by providing `class_` argument. Beasutiful soup uses `class_` because `class` is a reserved keyword in python. For example, let's search for `p` tags that have element `story`.\n\n::: {#e9d316f0 .cell execution_count=17}\n``` {.python .cell-code}\nsoup.find_all(\"p\", class_ = \"title\")\n```\n\n::: {.cell-output .cell-output-display execution_count=72}\n```\n[<p class=\"title\"><b>The Dormouse's story</b></p>]\n```\n:::\n:::\n\n\n::: {#6e356e1d .cell execution_count=18}\n``` {.python .cell-code}\nsoup.find(\"p\", class_=\"story\")\n```\n\n::: {.cell-output .cell-output-display execution_count=73}\n```\n<p class=\"story\">Once upon a time there were three little sisters; and their names were\n<a class=\"sister\" href=\"http://example.com/elsie\" id=\"link1\">Elsie</a>,\n<a class=\"sister\" href=\"http://example.com/lacie\" id=\"link2\">Lacie</a> and\n<a class=\"sister\" href=\"http://example.com/tillie\" id=\"link3\">Tillie</a>;\nand they lived at the bottom of a well.</p>\n```\n:::\n:::\n\n\n::: {#baa7160e .cell execution_count=19}\n``` {.python .cell-code}\nsoup.find(\"p\", class_=\"story\").get_text()\n```\n\n::: {.cell-output .cell-output-display execution_count=74}\n```\n'Once upon a time there were three little sisters; and their names were\\nElsie,\\nLacie and\\nTillie;\\nand they lived at the bottom of a well.'\n```\n:::\n:::\n\n\n:::\n\n## Scrape a Website Using BeautifulSoup {#sec-usebeautifulsoup}\n\n::: {style=\"text-align: justify\"}\n     We have mastered some basic knowledge of Beautifulsoup. Therefore, it is now time to put our knowledge into practice. We are going to parse a [website](https://books.toscrape.com/catalogue/page-1.html), which includes information about books. We would like to extract some data from the website. The data include - book url, title of the book, ratings of the book, price, and availability of the book. Before we start scraping the website, we need to identify the tags or CSS selectors that are relevant for our targeted data. @fig-webscrapeExample shows how we can identify the tags or selectors relevant for our search. We should hover our cursor over the information that we plan to extract and then click right button of the mouse (on Windows) and click `\"inspect\"`. Then we can see all tags and CSS selectors and other tags of the website. @fig-webscrapeExample visualizes the whole process.\n\n![How to Find the HTML tags and CSS Class](images/first_webscraping2.gif){#fig-webscrapeExample}\n\n     First, we need to import necessary python modules. We use `requests` module to get the website information.\n\n::: {#4b7bf901 .cell execution_count=20}\n``` {.python .cell-code}\n# importing requests \nimport requests\n# importing beautifulsoup\nfrom bs4 import BeautifulSoup\n# importing pandas \nimport pandas as pd\n```\n:::\n\n\n     Then, we convert the data into `soup` object.\n\n::: {#d6e8acac .cell execution_count=21}\n``` {.python .cell-code}\n# Fetch the website page \nurl = 'https://books.toscrape.com/catalogue/page-1.html'\nhtml = requests.get(url)\npage = html.text\n# Converting it into Soup Object \nsoup = BeautifulSoup(page, \"html.parser\")\n```\n:::\n\n\n     After inspecting the tags and CSS selectors, we identify that `article` tag and `product_pod` class contains the information that we would like to extract. We use the `find` function from `beautifulsuop` to see our expected data. As noted before, `find` function identifies the first instance of the elements whereas `find_all` identifies all elements of the parsed HTML.\n\n::: {#27320c86 .cell execution_count=22}\n``` {.python .cell-code}\nsoup.find(\"article\", class_=\"product_pod\")\n```\n\n::: {.cell-output .cell-output-display execution_count=77}\n```\n<article class=\"product_pod\">\n<div class=\"image_container\">\n<a href=\"a-light-in-the-attic_1000/index.html\"><img alt=\"A Light in the Attic\" class=\"thumbnail\" src=\"../media/cache/2c/da/2cdad67c44b002e7ead0cc35693c0e8b.jpg\"/></a>\n</div>\n<p class=\"star-rating Three\">\n<i class=\"icon-star\"></i>\n<i class=\"icon-star\"></i>\n<i class=\"icon-star\"></i>\n<i class=\"icon-star\"></i>\n<i class=\"icon-star\"></i>\n</p>\n<h3><a href=\"a-light-in-the-attic_1000/index.html\" title=\"A Light in the Attic\">A Light in the ...</a></h3>\n<div class=\"product_price\">\n<p class=\"price_color\">Â£51.77</p>\n<p class=\"instock availability\">\n<i class=\"icon-ok\"></i>\n    \n        In stock\n    \n</p>\n<form>\n<button class=\"btn btn-primary btn-block\" data-loading-text=\"Adding...\" type=\"submit\">Add to basket</button>\n</form>\n</div>\n</article>\n```\n:::\n:::\n\n\n::: {#f836f5a5 .cell execution_count=23}\n``` {.python .cell-code}\nsoup.find_all(\"article\", class_=\"product_pod\")\n```\n:::\n\n\n     Next, we check the url of each book. The `a` tag defines a hyperlink and the `href` is an attribute of `a` tag. Below, we use `a` tag to identify the link of each book.\n\n::: {#34f63635 .cell execution_count=24}\n``` {.python .cell-code}\nbooks = soup.find_all(\"article\", class_=\"product_pod\")\n```\n:::\n\n\n::: {#aaadca23 .cell execution_count=25}\n``` {.python .cell-code}\nsource_url = \"https://books.toscrape.com/catalogue\"\n```\n:::\n\n\n::: {#3833d422 .cell execution_count=26}\n``` {.python .cell-code}\n# Book url \nfor h in soup.find_all(\"article\", class_=\"product_pod\"):\n    print(source_url+\"/\"+h.find('a')['href'])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nhttps://books.toscrape.com/catalogue/a-light-in-the-attic_1000/index.html\nhttps://books.toscrape.com/catalogue/tipping-the-velvet_999/index.html\nhttps://books.toscrape.com/catalogue/soumission_998/index.html\nhttps://books.toscrape.com/catalogue/sharp-objects_997/index.html\nhttps://books.toscrape.com/catalogue/sapiens-a-brief-history-of-humankind_996/index.html\nhttps://books.toscrape.com/catalogue/the-requiem-red_995/index.html\nhttps://books.toscrape.com/catalogue/the-dirty-little-secrets-of-getting-your-dream-job_994/index.html\nhttps://books.toscrape.com/catalogue/the-coming-woman-a-novel-based-on-the-life-of-the-infamous-feminist-victoria-woodhull_993/index.html\nhttps://books.toscrape.com/catalogue/the-boys-in-the-boat-nine-americans-and-their-epic-quest-for-gold-at-the-1936-berlin-olympics_992/index.html\nhttps://books.toscrape.com/catalogue/the-black-maria_991/index.html\nhttps://books.toscrape.com/catalogue/starving-hearts-triangular-trade-trilogy-1_990/index.html\nhttps://books.toscrape.com/catalogue/shakespeares-sonnets_989/index.html\nhttps://books.toscrape.com/catalogue/set-me-free_988/index.html\nhttps://books.toscrape.com/catalogue/scott-pilgrims-precious-little-life-scott-pilgrim-1_987/index.html\nhttps://books.toscrape.com/catalogue/rip-it-up-and-start-again_986/index.html\nhttps://books.toscrape.com/catalogue/our-band-could-be-your-life-scenes-from-the-american-indie-underground-1981-1991_985/index.html\nhttps://books.toscrape.com/catalogue/olio_984/index.html\nhttps://books.toscrape.com/catalogue/mesaerion-the-best-science-fiction-stories-1800-1849_983/index.html\nhttps://books.toscrape.com/catalogue/libertarianism-for-beginners_982/index.html\nhttps://books.toscrape.com/catalogue/its-only-the-himalayas_981/index.html\n```\n:::\n:::\n\n\n::: {#e4d022df .cell execution_count=27}\n``` {.python .cell-code}\n# Book url (Alternative) \nfor h in soup.find_all(\"article\", class_=\"product_pod\"):\n    print(h.h3.find('a')['href'])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\na-light-in-the-attic_1000/index.html\ntipping-the-velvet_999/index.html\nsoumission_998/index.html\nsharp-objects_997/index.html\nsapiens-a-brief-history-of-humankind_996/index.html\nthe-requiem-red_995/index.html\nthe-dirty-little-secrets-of-getting-your-dream-job_994/index.html\nthe-coming-woman-a-novel-based-on-the-life-of-the-infamous-feminist-victoria-woodhull_993/index.html\nthe-boys-in-the-boat-nine-americans-and-their-epic-quest-for-gold-at-the-1936-berlin-olympics_992/index.html\nthe-black-maria_991/index.html\nstarving-hearts-triangular-trade-trilogy-1_990/index.html\nshakespeares-sonnets_989/index.html\nset-me-free_988/index.html\nscott-pilgrims-precious-little-life-scott-pilgrim-1_987/index.html\nrip-it-up-and-start-again_986/index.html\nour-band-could-be-your-life-scenes-from-the-american-indie-underground-1981-1991_985/index.html\nolio_984/index.html\nmesaerion-the-best-science-fiction-stories-1800-1849_983/index.html\nlibertarianism-for-beginners_982/index.html\nits-only-the-himalayas_981/index.html\n```\n:::\n:::\n\n\n::: {#8a3298fe .cell execution_count=28}\n``` {.python .cell-code}\n# Book Title \nfor h in soup.find_all(\"article\", class_=\"product_pod\"):\n    print(h.h3.find('a')['title'])\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nA Light in the Attic\nTipping the Velvet\nSoumission\nSharp Objects\nSapiens: A Brief History of Humankind\nThe Requiem Red\nThe Dirty Little Secrets of Getting Your Dream Job\nThe Coming Woman: A Novel Based on the Life of the Infamous Feminist, Victoria Woodhull\nThe Boys in the Boat: Nine Americans and Their Epic Quest for Gold at the 1936 Berlin Olympics\nThe Black Maria\nStarving Hearts (Triangular Trade Trilogy, #1)\nShakespeare's Sonnets\nSet Me Free\nScott Pilgrim's Precious Little Life (Scott Pilgrim #1)\nRip it Up and Start Again\nOur Band Could Be Your Life: Scenes from the American Indie Underground, 1981-1991\nOlio\nMesaerion: The Best Science Fiction Stories 1800-1849\nLibertarianism for Beginners\nIt's Only the Himalayas\n```\n:::\n:::\n\n\n::: {#1a2b5f6b .cell execution_count=29}\n``` {.python .cell-code}\n# ratings \nsoup.find('p', class_='star-rating')['class'][1]\n```\n\n::: {.cell-output .cell-output-display execution_count=83}\n```\n'Three'\n```\n:::\n:::\n\n\n::: {#c6e1a3f9 .cell execution_count=30}\n``` {.python .cell-code}\n# price \nsoup.find('p', class_='price_color').get_text().replace(\"Â\",'')\n```\n\n::: {.cell-output .cell-output-display execution_count=84}\n```\n'£51.77'\n```\n:::\n:::\n\n\n::: {#dc83eb9e .cell execution_count=31}\n``` {.python .cell-code}\n# availability \nsoup.find('p', class_='instock availability').get_text().replace('\\n','').strip()\n```\n\n::: {.cell-output .cell-output-display execution_count=85}\n```\n'In stock'\n```\n:::\n:::\n\n\n### Putting All of the Above Actions Together {#sec-onepage}\n\n     In @sec-usebeautifulsoup, we identify and extract individual tags and data that we want to extract. Now, we will put all of them together and create a data frame. For this purpose, we will use `for loop`.\n\n::: {#7dcfa2ce .cell execution_count=32}\n``` {.python .cell-code}\n# Fetch the Page \nurl = 'https://books.toscrape.com/catalogue/page-1.html'\nhtml = requests.get(url)\npage = html.text\n# Parse HTML Content\nsoup = BeautifulSoup(page, \"html.parser\")\n\n# Information We need \n\nbook_url = []\ntitle = []\nratings = []\nprice = []\navailability = []\n\n# Extract listings from the page\nbooks = soup.find_all(\"article\", class_=\"product_pod\")\nsource_url = \"https://books.toscrape.com/catalogue\"\n\nfor book in books:\n    # extract book url \n    book_url_text = source_url+\"/\"+book.find('a')['href']\n    book_url.append(book_url_text)\n\n    # extract title \n    title_text = book.h3.find('a')['title']\n    title.append(title_text)\n\n    # extract ratings \n    ratings_text = book.find('p', class_='star-rating')['class'][1]\n    ratings.append(ratings_text)\n\n    # extract price \n    price_text = book.find('p', class_='price_color').get_text().replace(\"Â\",'')\n    price.append(price_text)\n\n    # extract availability \n    availability_text = book.find('p', class_='instock availability').get_text().replace('\\n','').strip()\n    availability.append(availability_text)\n\n# Creating the Data Frame \n\npd.DataFrame({\n    'book_url':book_url,\n    'title':title,\n    'ratings':ratings,\n    'price':price,\n    'availability':availability\n})\n\n```\n\n::: {.cell-output .cell-output-display execution_count=86}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>book_url</th>\n      <th>title</th>\n      <th>ratings</th>\n      <th>price</th>\n      <th>availability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://books.toscrape.com/catalogue/a-light-i...</td>\n      <td>A Light in the Attic</td>\n      <td>Three</td>\n      <td>£51.77</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://books.toscrape.com/catalogue/tipping-t...</td>\n      <td>Tipping the Velvet</td>\n      <td>One</td>\n      <td>£53.74</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://books.toscrape.com/catalogue/soumissio...</td>\n      <td>Soumission</td>\n      <td>One</td>\n      <td>£50.10</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://books.toscrape.com/catalogue/sharp-obj...</td>\n      <td>Sharp Objects</td>\n      <td>Four</td>\n      <td>£47.82</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://books.toscrape.com/catalogue/sapiens-a...</td>\n      <td>Sapiens: A Brief History of Humankind</td>\n      <td>Five</td>\n      <td>£54.23</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>https://books.toscrape.com/catalogue/the-requi...</td>\n      <td>The Requiem Red</td>\n      <td>One</td>\n      <td>£22.65</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>https://books.toscrape.com/catalogue/the-dirty...</td>\n      <td>The Dirty Little Secrets of Getting Your Dream...</td>\n      <td>Four</td>\n      <td>£33.34</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>https://books.toscrape.com/catalogue/the-comin...</td>\n      <td>The Coming Woman: A Novel Based on the Life of...</td>\n      <td>Three</td>\n      <td>£17.93</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>https://books.toscrape.com/catalogue/the-boys-...</td>\n      <td>The Boys in the Boat: Nine Americans and Their...</td>\n      <td>Four</td>\n      <td>£22.60</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>https://books.toscrape.com/catalogue/the-black...</td>\n      <td>The Black Maria</td>\n      <td>One</td>\n      <td>£52.15</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>https://books.toscrape.com/catalogue/starving-...</td>\n      <td>Starving Hearts (Triangular Trade Trilogy, #1)</td>\n      <td>Two</td>\n      <td>£13.99</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>https://books.toscrape.com/catalogue/shakespea...</td>\n      <td>Shakespeare's Sonnets</td>\n      <td>Four</td>\n      <td>£20.66</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>https://books.toscrape.com/catalogue/set-me-fr...</td>\n      <td>Set Me Free</td>\n      <td>Five</td>\n      <td>£17.46</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>https://books.toscrape.com/catalogue/scott-pil...</td>\n      <td>Scott Pilgrim's Precious Little Life (Scott Pi...</td>\n      <td>Five</td>\n      <td>£52.29</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>https://books.toscrape.com/catalogue/rip-it-up...</td>\n      <td>Rip it Up and Start Again</td>\n      <td>Five</td>\n      <td>£35.02</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>https://books.toscrape.com/catalogue/our-band-...</td>\n      <td>Our Band Could Be Your Life: Scenes from the A...</td>\n      <td>Three</td>\n      <td>£57.25</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>https://books.toscrape.com/catalogue/olio_984/...</td>\n      <td>Olio</td>\n      <td>One</td>\n      <td>£23.88</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>https://books.toscrape.com/catalogue/mesaerion...</td>\n      <td>Mesaerion: The Best Science Fiction Stories 18...</td>\n      <td>One</td>\n      <td>£37.59</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>https://books.toscrape.com/catalogue/libertari...</td>\n      <td>Libertarianism for Beginners</td>\n      <td>Two</td>\n      <td>£51.33</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>https://books.toscrape.com/catalogue/its-only-...</td>\n      <td>It's Only the Himalayas</td>\n      <td>Two</td>\n      <td>£45.17</td>\n      <td>In stock</td>\n    </tr>\n  </tbody>\n</table>\n</div>\n```\n:::\n:::\n\n\n### Doing the Same Things for All Pages\n\n     In @sec-onepage, we scrape the first page of the website, but now we would like to scrape all pages of the website.\n\n::: {#976111c1 .cell execution_count=33}\n``` {.python .cell-code}\nurl1 = 'https://books.toscrape.com/catalogue/page-'\npages = range(51)\nurl2 = '.html'\n\n# Information We need \nbook_url = []\ntitle = []\nratings = []\nprice = []\navailability = []\n# Some other Information \nsource_url = \"https://books.toscrape.com/catalogue\"\n\nfor page in pages:\n    url = url1+str(page)+url2\n    r = requests.get(url)\n    soup = BeautifulSoup(r.text, 'html.parser')\n    books = soup.find_all(\"article\", class_=\"product_pod\")\n\n    for book in books:\n        # extract book url \n        book_url_text = source_url+\"/\"+book.find('a')['href']\n        book_url.append(book_url_text)\n\n        # extract title \n        title_text = book.h3.find('a')['title']\n        title.append(title_text)\n\n        # extract ratings \n        ratings_text = book.find('p', class_='star-rating')['class'][1]\n        ratings.append(ratings_text)\n\n        # extract price \n        price_text = book.find('p', class_='price_color').get_text().replace(\"Â\",'')\n        price.append(price_text)\n\n        # extract availability \n        availability_text = book.find('p', class_='instock availability').get_text().replace('\\n','').strip()\n        availability.append(availability_text)\n    \n\n\n\n# Creating the Data Frame \npd.DataFrame({\n    'book_url':book_url,\n    'title':title,\n    'ratings':ratings,\n    'price':price,\n    'availability':availability\n})\n```\n\n::: {.cell-output .cell-output-display execution_count=87}\n```{=html}\n<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>book_url</th>\n      <th>title</th>\n      <th>ratings</th>\n      <th>price</th>\n      <th>availability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>https://books.toscrape.com/catalogue/a-light-i...</td>\n      <td>A Light in the Attic</td>\n      <td>Three</td>\n      <td>£51.77</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>https://books.toscrape.com/catalogue/tipping-t...</td>\n      <td>Tipping the Velvet</td>\n      <td>One</td>\n      <td>£53.74</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>https://books.toscrape.com/catalogue/soumissio...</td>\n      <td>Soumission</td>\n      <td>One</td>\n      <td>£50.10</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>https://books.toscrape.com/catalogue/sharp-obj...</td>\n      <td>Sharp Objects</td>\n      <td>Four</td>\n      <td>£47.82</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>https://books.toscrape.com/catalogue/sapiens-a...</td>\n      <td>Sapiens: A Brief History of Humankind</td>\n      <td>Five</td>\n      <td>£54.23</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>995</th>\n      <td>https://books.toscrape.com/catalogue/alice-in-...</td>\n      <td>Alice in Wonderland (Alice's Adventures in Won...</td>\n      <td>One</td>\n      <td>£55.53</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>996</th>\n      <td>https://books.toscrape.com/catalogue/ajin-demi...</td>\n      <td>Ajin: Demi-Human, Volume 1 (Ajin: Demi-Human #1)</td>\n      <td>Four</td>\n      <td>£57.06</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>997</th>\n      <td>https://books.toscrape.com/catalogue/a-spys-de...</td>\n      <td>A Spy's Devotion (The Regency Spies of London #1)</td>\n      <td>Five</td>\n      <td>£16.97</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>998</th>\n      <td>https://books.toscrape.com/catalogue/1st-to-di...</td>\n      <td>1st to Die (Women's Murder Club #1)</td>\n      <td>One</td>\n      <td>£53.98</td>\n      <td>In stock</td>\n    </tr>\n    <tr>\n      <th>999</th>\n      <td>https://books.toscrape.com/catalogue/1000-plac...</td>\n      <td>1,000 Places to See Before You Die</td>\n      <td>Five</td>\n      <td>£26.08</td>\n      <td>In stock</td>\n    </tr>\n  </tbody>\n</table>\n<p>1000 rows × 5 columns</p>\n</div>\n```\n:::\n:::\n\n\n:::\n\n\n::: {style=\"text-align: justify\"}\n## Conclusion\n\n     On this chapter, we discuss about how to collect unstructured data, particularly collecting data from websites. The structure of HTML taggings and CSS selectors are highlighted because they are very important to understand how to scrape a website. Moreover, we scrape a page of a website and finally we demonstrated how to extract data from multiple pages of a website and convert them into a data frame. \n\n:::\n\n",
    "supporting": [
      "advanced_analytics_files"
    ],
    "filters": [],
    "includes": {
      "include-in-header": [
        "<script src=\"https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js\" integrity=\"sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==\" crossorigin=\"anonymous\"></script>\n<script src=\"https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js\" integrity=\"sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==\" crossorigin=\"anonymous\" data-relocate-top=\"true\"></script>\n<script type=\"application/javascript\">define('jquery', [],function() {return window.jQuery;})</script>\n"
      ]
    }
  }
}