[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Analytics for Accounting Data",
    "section": "",
    "text": "Welcome\nWelcome to the book - Analytics for Accounting Data - which is slated to be published future. It will be available for purchase in both paperback and hardback, with pre-ordering available on both Amazon and online.\nThis is the online version of the book, which is free to use. The book is being developed. So it is recommended to use the book with caution. More chapters and materials wil be added to the book gradually.\nIf you want me to add some materials that are necessary for the students, please do not hesitate to ask. All kinds of comments, recommendations, suggestions, criticisms are welcome.\n\n\n\n\n\n\nWarning\n\n\n\nThis book is a work in progress.\n\n\n\n\nPreface\n\n\nAbout the Book\nThe book is written for the students in undergraduate and graduate programs.\n\n\nAbout the Author\n\n\n\n\nSharif Islam, DBA, CPA, CMA is an Assistant professor in School of Accountancy in Southern Illinois University Carbondale (SIUC). He is a licensed CPA in Illinois and a Certified Management Accountant (CMA). He teaches Auditing, Accounting Information Systems, Machine Learning, and Analytics for Accounting Data. He did his doctorate from Louisiana Tech University in Computer Information Systems and Accounting. His mansucripts are selected for “Best Research Paper Award” in several conferences of American Accounting Association (AAA). His research also got 2024 “Notable Contribution to the Literature Award” by AIS section of AAA. He published research in Accounting Horizons, Journal of Accounting and Public Policy, Journal of Emerging Technologies in Accounting, Issues in Accounting Education, Advances in Accounting and Managerial Auditing Journal. His research interests lie at the intersection of Accounting and Data Science.\n\n\n\nHow to Read the Book\n\n\nAcknowledgment\n\nTo prepare the book, I took help from many sources on the internet and published materials. Many of them are cited in the book. I acknowledge the contribution of all of those resources that help me to prepare the book for the students.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "3  Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "Learning Objectives of the Chapter",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Exploratory Data Analysis (EDA)</span>"
    ]
  },
  {
    "objectID": "eda.html#introduction",
    "href": "eda.html#introduction",
    "title": "3  Exploratory Data Analysis (EDA)",
    "section": "3.1 Introduction",
    "text": "3.1 Introduction\n\n     In descriptive statistics, we summarize the data using different metrics such as mean, median, standard deviation, minimum value, maximum value, and percentile. Descriptive statisics is also called summary statistics.",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Exploratory Data Analysis (EDA)</span>"
    ]
  },
  {
    "objectID": "eda.html#data-collection-importing",
    "href": "eda.html#data-collection-importing",
    "title": "3  Exploratory Data Analysis (EDA)",
    "section": "3.2 Data Collection & Importing",
    "text": "3.2 Data Collection & Importing",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Exploratory Data Analysis (EDA)</span>"
    ]
  },
  {
    "objectID": "eda.html#data-cleaning",
    "href": "eda.html#data-cleaning",
    "title": "3  Exploratory Data Analysis (EDA)",
    "section": "3.3 Data Cleaning",
    "text": "3.3 Data Cleaning",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Exploratory Data Analysis (EDA)</span>"
    ]
  },
  {
    "objectID": "eda.html#packages-for-exploratory-data-analysis-eda",
    "href": "eda.html#packages-for-exploratory-data-analysis-eda",
    "title": "3  Exploratory Data Analysis (EDA)",
    "section": "3.4 Packages for Exploratory Data Analysis (EDA)",
    "text": "3.4 Packages for Exploratory Data Analysis (EDA)\n\n     In order to use pyjanitor, the data frame must be pandas because pyjanitor extends pandas data frame functionality.\n\n\ndplyrpandas\n\n\n\n# loading packages\nlibrary(tidyverse)\nlibrary(lubridate)\nlibrary(janitor)\n\n\n\n\n# loading the package\nimport numpy as np\nimport pandas as pd\n# from pyjanitor package \n# pip install pyjanitor\nimport janitor \nfrom janitor import clean_names, remove_empty",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Exploratory Data Analysis (EDA)</span>"
    ]
  },
  {
    "objectID": "eda.html#importing-the-dataset",
    "href": "eda.html#importing-the-dataset",
    "title": "3  Exploratory Data Analysis (EDA)",
    "section": "3.5 Importing the Dataset",
    "text": "3.5 Importing the Dataset\n\ndplyrpandas\n\n\n\n# importing data frame \ndf = read_csv(\"https://raw.githubusercontent.com/msharifbd/DATA/main/Al-Bundy_raw-data.csv\")\n\n\n\n\n# importing data frame \ndf_pd = pd.read_csv(\"https://raw.githubusercontent.com/msharifbd/DATA/main/Al-Bundy_raw-data.csv\")",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Exploratory Data Analysis (EDA)</span>"
    ]
  },
  {
    "objectID": "eda.html#meta-data",
    "href": "eda.html#meta-data",
    "title": "3  Exploratory Data Analysis (EDA)",
    "section": "3.6 Meta Data",
    "text": "3.6 Meta Data\n\n     Meta data is data about the data. Before we put the data into analysis, we need to learn about our dataset. This learning invovles knowing about the number of rows, number of columns, the types of the fields, the appropriateness of those types, the missing values in the dataset and so on.\n\n\ndplyrPandas\n\n\n\nglimpse(df)\n\nRows: 14,967\nColumns: 14\n$ InvoiceNo       &lt;dbl&gt; 52389, 52390, 52391, 52392, 52393, 52394, 52395, 52396…\n$ Date            &lt;chr&gt; \"1/1/2014\", \"1/1/2014\", \"1/1/2014\", \"1/1/2014\", \"1/1/2…\n$ Country         &lt;chr&gt; \"United Kingdom\", \"United States\", \"Canada\", \"United S…\n$ ProductID       &lt;dbl&gt; 2152, 2230, 2160, 2234, 2222, 2173, 2200, 2238, 2191, …\n$ Shop            &lt;chr&gt; \"UK2\", \"US15\", \"CAN7\", \"US6\", \"UK4\", \"US15\", \"GER2\", \"…\n$ Gender          &lt;chr&gt; \"Male\", \"Male\", \"Male\", \"Female\", \"Female\", \"Male\", \"F…\n$ `Size (US)`     &lt;dbl&gt; 11.0, 11.5, 9.5, 9.5, 9.0, 10.5, 9.0, 10.0, 10.5, 9.0,…\n$ `Size (Europe)` &lt;chr&gt; \"44\", \"44-45\", \"42-43\", \"40\", \"39-40\", \"43-44\", \"39-40…\n$ `Size (UK)`     &lt;dbl&gt; 10.5, 11.0, 9.0, 7.5, 7.0, 10.0, 7.0, 9.5, 10.0, 7.0, …\n$ UnitPrice       &lt;dbl&gt; 159, 199, 149, 159, 159, 159, 179, 169, 139, 149, 129,…\n$ Discount        &lt;dbl&gt; 0.0, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,…\n$ Year            &lt;dbl&gt; 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, …\n$ Month           &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ SalePrice       &lt;dbl&gt; 159.0, 159.2, 119.2, 159.0, 159.0, 159.0, 179.0, 169.0…\n\n\n\nmap_df(df, ~sum(is.na(.))) |&gt;\n     glimpse()\n\nRows: 1\nColumns: 14\n$ InvoiceNo       &lt;int&gt; 0\n$ Date            &lt;int&gt; 0\n$ Country         &lt;int&gt; 0\n$ ProductID       &lt;int&gt; 0\n$ Shop            &lt;int&gt; 0\n$ Gender          &lt;int&gt; 0\n$ `Size (US)`     &lt;int&gt; 0\n$ `Size (Europe)` &lt;int&gt; 0\n$ `Size (UK)`     &lt;int&gt; 0\n$ UnitPrice       &lt;int&gt; 0\n$ Discount        &lt;int&gt; 0\n$ Year            &lt;int&gt; 0\n$ Month           &lt;int&gt; 0\n$ SalePrice       &lt;int&gt; 0\n\n\n\nncol(df)\n\n[1] 14\n\nnrow(df)\n\n[1] 14967\n\n\n\nhead(df)\n\n# A tibble: 6 × 14\n  InvoiceNo Date     Country  ProductID Shop  Gender `Size (US)` `Size (Europe)`\n      &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;          \n1     52389 1/1/2014 United …      2152 UK2   Male          11   44             \n2     52390 1/1/2014 United …      2230 US15  Male          11.5 44-45          \n3     52391 1/1/2014 Canada        2160 CAN7  Male           9.5 42-43          \n4     52392 1/1/2014 United …      2234 US6   Female         9.5 40             \n5     52393 1/1/2014 United …      2222 UK4   Female         9   39-40          \n6     52394 1/1/2014 United …      2173 US15  Male          10.5 43-44          \n# ℹ 6 more variables: `Size (UK)` &lt;dbl&gt;, UnitPrice &lt;dbl&gt;, Discount &lt;dbl&gt;,\n#   Year &lt;dbl&gt;, Month &lt;dbl&gt;, SalePrice &lt;dbl&gt;\n\n\n\ntail(df)\n\n# A tibble: 6 × 14\n  InvoiceNo Date      Country ProductID Shop  Gender `Size (US)` `Size (Europe)`\n      &lt;dbl&gt; &lt;chr&gt;     &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;          \n1     65772 12/31/20… United…      2168 US13  Male           8   41             \n2     65773 12/31/20… United…      2154 UK2   Male           9.5 42-43          \n3     65774 12/31/20… United…      2181 US12  Female        12   42-43          \n4     65775 12/31/20… Canada       2203 CAN6  Male          10.5 43-44          \n5     65776 12/31/20… Germany      2231 GER1  Female         9.5 40             \n6     65777 12/31/20… Germany      2156 GER1  Female         6.5 37             \n# ℹ 6 more variables: `Size (UK)` &lt;dbl&gt;, UnitPrice &lt;dbl&gt;, Discount &lt;dbl&gt;,\n#   Year &lt;dbl&gt;, Month &lt;dbl&gt;, SalePrice &lt;dbl&gt;\n\n\n\ndplyr::sample_n(df, 10)\n\n# A tibble: 10 × 14\n   InvoiceNo Date     Country ProductID Shop  Gender `Size (US)` `Size (Europe)`\n       &lt;dbl&gt; &lt;chr&gt;    &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt;        &lt;dbl&gt; &lt;chr&gt;          \n 1     64836 10/30/2… Germany      2179 GER3  Female         9.5 40             \n 2     59961 2/18/20… Germany      2203 GER1  Male          10.5 43-44          \n 3     63386 8/20/20… Germany      2229 GER2  Male           9   42             \n 4     56567 6/22/20… United…      2201 US11  Female         6.5 37             \n 5     58121 10/16/2… Canada       2198 CAN5  Female         9   39-40          \n 6     60712 4/4/2016 United…      2192 US6   Female        11   41-42          \n 7     55017 2/1/2015 Canada       2185 CAN6  Female         6   36-37          \n 8     57635 9/10/20… Germany      2172 GER1  Female         9.5 40             \n 9     56235 5/29/20… United…      2201 UK3   Male          10.5 43-44          \n10     65411 12/5/20… Germany      2168 GER1  Male           9.5 42-43          \n# ℹ 6 more variables: `Size (UK)` &lt;dbl&gt;, UnitPrice &lt;dbl&gt;, Discount &lt;dbl&gt;,\n#   Year &lt;dbl&gt;, Month &lt;dbl&gt;, SalePrice &lt;dbl&gt;\n\n\n\n\n\ndf_pd.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 14967 entries, 0 to 14966\nData columns (total 14 columns):\n #   Column         Non-Null Count  Dtype  \n---  ------         --------------  -----  \n 0   InvoiceNo      14967 non-null  int64  \n 1   Date           14967 non-null  object \n 2   Country        14967 non-null  object \n 3   ProductID      14967 non-null  int64  \n 4   Shop           14967 non-null  object \n 5   Gender         14967 non-null  object \n 6   Size (US)      14967 non-null  float64\n 7   Size (Europe)  14967 non-null  object \n 8   Size (UK)      14967 non-null  float64\n 9   UnitPrice      14967 non-null  int64  \n 10  Discount       14967 non-null  float64\n 11  Year           14967 non-null  int64  \n 12  Month          14967 non-null  int64  \n 13  SalePrice      14967 non-null  float64\ndtypes: float64(4), int64(5), object(5)\nmemory usage: 1.6+ MB\n\n\n\ndf_pd.shape\n\n(14967, 14)\n\n\n\nprint('The total number of rows and columns of the product data is \\\n {} and {} respectively.'.format(df_pd.shape[0], df_pd.shape[1]))\n\nThe total number of rows and columns of the product data is  14967 and 14 respectively.\n\n\n\nprint(f'The total number of rows and columns of the product data is \\\n {df_pd.shape[0]} and {df_pd.shape[1]} respectively.')\n\nThe total number of rows and columns of the product data is  14967 and 14 respectively.\n\n\n\ndf_pd.columns\n\nIndex(['InvoiceNo', 'Date', 'Country', 'ProductID', 'Shop', 'Gender',\n       'Size (US)', 'Size (Europe)', 'Size (UK)', 'UnitPrice', 'Discount',\n       'Year', 'Month', 'SalePrice'],\n      dtype='object')\n\n\n\ndf_pd.head()\n\n   InvoiceNo      Date         Country  ...  Year Month SalePrice\n0      52389  1/1/2014  United Kingdom  ...  2014     1     159.0\n1      52390  1/1/2014   United States  ...  2014     1     159.2\n2      52391  1/1/2014          Canada  ...  2014     1     119.2\n3      52392  1/1/2014   United States  ...  2014     1     159.0\n4      52393  1/1/2014  United Kingdom  ...  2014     1     159.0\n\n[5 rows x 14 columns]\n\n\n\ndf_pd.tail()\n\n       InvoiceNo        Date         Country  ...  Year Month SalePrice\n14962      65773  12/31/2016  United Kingdom  ...  2016    12     139.0\n14963      65774  12/31/2016   United States  ...  2016    12     149.0\n14964      65775  12/31/2016          Canada  ...  2016    12     125.3\n14965      65776  12/31/2016         Germany  ...  2016    12     199.0\n14966      65777  12/31/2016         Germany  ...  2016    12     125.1\n\n[5 rows x 14 columns]\n\n\n\ndf_pd.isna().sum()\n\nInvoiceNo        0\nDate             0\nCountry          0\nProductID        0\nShop             0\nGender           0\nSize (US)        0\nSize (Europe)    0\nSize (UK)        0\nUnitPrice        0\nDiscount         0\nYear             0\nMonth            0\nSalePrice        0\ndtype: int64\n\n\n\ndf_pd.dtypes\n\nInvoiceNo          int64\nDate              object\nCountry           object\nProductID          int64\nShop              object\nGender            object\nSize (US)        float64\nSize (Europe)     object\nSize (UK)        float64\nUnitPrice          int64\nDiscount         float64\nYear               int64\nMonth              int64\nSalePrice        float64\ndtype: object\n\n\n\ndf_pd.sample(n=10)\n\n       InvoiceNo        Date        Country  ...  Year Month SalePrice\n14820      65636  12/20/2016  United States  ...  2016    12     189.0\n4198       56062   5/14/2015  United States  ...  2015     5     139.0\n2887       54856   1/15/2015         Canada  ...  2015     1     125.1\n13925      64820  10/29/2016        Germany  ...  2016    10      84.5\n2735       54709  12/30/2014         Canada  ...  2014    12      89.5\n8647       60131   2/27/2016  United States  ...  2016     2     129.0\n8617       60102   2/26/2016        Germany  ...  2016     2     134.1\n6959       58608  11/18/2015  United States  ...  2015    11     169.0\n13977      64864  10/31/2016  United States  ...  2016    10     139.0\n1939       54041   9/14/2014  United States  ...  2014     9     161.1\n\n[10 rows x 14 columns]",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Exploratory Data Analysis (EDA)</span>"
    ]
  },
  {
    "objectID": "eda.html#cleaning-the-dataset",
    "href": "eda.html#cleaning-the-dataset",
    "title": "3  Exploratory Data Analysis (EDA)",
    "section": "3.7 Cleaning the Dataset",
    "text": "3.7 Cleaning the Dataset\n\ndplyrpanads\n\n\n\n df |&gt;\n     rename_all(toupper) |&gt;\n     janitor::clean_names() |&gt;\n     rename_all(toupper) |&gt;\n     glimpse()\n\nRows: 14,967\nColumns: 14\n$ INVOICENO   &lt;dbl&gt; 52389, 52390, 52391, 52392, 52393, 52394, 52395, 52396, 52…\n$ DATE        &lt;chr&gt; \"1/1/2014\", \"1/1/2014\", \"1/1/2014\", \"1/1/2014\", \"1/1/2014\"…\n$ COUNTRY     &lt;chr&gt; \"United Kingdom\", \"United States\", \"Canada\", \"United State…\n$ PRODUCTID   &lt;dbl&gt; 2152, 2230, 2160, 2234, 2222, 2173, 2200, 2238, 2191, 2237…\n$ SHOP        &lt;chr&gt; \"UK2\", \"US15\", \"CAN7\", \"US6\", \"UK4\", \"US15\", \"GER2\", \"CAN5…\n$ GENDER      &lt;chr&gt; \"Male\", \"Male\", \"Male\", \"Female\", \"Female\", \"Male\", \"Femal…\n$ SIZE_US     &lt;dbl&gt; 11.0, 11.5, 9.5, 9.5, 9.0, 10.5, 9.0, 10.0, 10.5, 9.0, 10.…\n$ SIZE_EUROPE &lt;chr&gt; \"44\", \"44-45\", \"42-43\", \"40\", \"39-40\", \"43-44\", \"39-40\", \"…\n$ SIZE_UK     &lt;dbl&gt; 10.5, 11.0, 9.0, 7.5, 7.0, 10.0, 7.0, 9.5, 10.0, 7.0, 9.5,…\n$ UNITPRICE   &lt;dbl&gt; 159, 199, 149, 159, 159, 159, 179, 169, 139, 149, 129, 169…\n$ DISCOUNT    &lt;dbl&gt; 0.0, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1…\n$ YEAR        &lt;dbl&gt; 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014…\n$ MONTH       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ SALEPRICE   &lt;dbl&gt; 159.0, 159.2, 119.2, 159.0, 159.0, 159.0, 179.0, 169.0, 13…\n\n\n\ndf = df |&gt;\n     rename_all(toupper) |&gt;\n     janitor::clean_names() |&gt;\n     rename_all(toupper)\nglimpse(df)\n\nRows: 14,967\nColumns: 14\n$ INVOICENO   &lt;dbl&gt; 52389, 52390, 52391, 52392, 52393, 52394, 52395, 52396, 52…\n$ DATE        &lt;chr&gt; \"1/1/2014\", \"1/1/2014\", \"1/1/2014\", \"1/1/2014\", \"1/1/2014\"…\n$ COUNTRY     &lt;chr&gt; \"United Kingdom\", \"United States\", \"Canada\", \"United State…\n$ PRODUCTID   &lt;dbl&gt; 2152, 2230, 2160, 2234, 2222, 2173, 2200, 2238, 2191, 2237…\n$ SHOP        &lt;chr&gt; \"UK2\", \"US15\", \"CAN7\", \"US6\", \"UK4\", \"US15\", \"GER2\", \"CAN5…\n$ GENDER      &lt;chr&gt; \"Male\", \"Male\", \"Male\", \"Female\", \"Female\", \"Male\", \"Femal…\n$ SIZE_US     &lt;dbl&gt; 11.0, 11.5, 9.5, 9.5, 9.0, 10.5, 9.0, 10.0, 10.5, 9.0, 10.…\n$ SIZE_EUROPE &lt;chr&gt; \"44\", \"44-45\", \"42-43\", \"40\", \"39-40\", \"43-44\", \"39-40\", \"…\n$ SIZE_UK     &lt;dbl&gt; 10.5, 11.0, 9.0, 7.5, 7.0, 10.0, 7.0, 9.5, 10.0, 7.0, 9.5,…\n$ UNITPRICE   &lt;dbl&gt; 159, 199, 149, 159, 159, 159, 179, 169, 139, 149, 129, 169…\n$ DISCOUNT    &lt;dbl&gt; 0.0, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1…\n$ YEAR        &lt;dbl&gt; 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014…\n$ MONTH       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ SALEPRICE   &lt;dbl&gt; 159.0, 159.2, 119.2, 159.0, 159.0, 159.0, 179.0, 169.0, 13…\n\n\n\n\n\ndf_pd.columns.str.upper().to_list()\n\n['INVOICENO', 'DATE', 'COUNTRY', 'PRODUCTID', 'SHOP', 'GENDER', 'SIZE (US)', 'SIZE (EUROPE)', 'SIZE (UK)', 'UNITPRICE', 'DISCOUNT', 'YEAR', 'MONTH', 'SALEPRICE']\n\n\n\n(df_pd\n     .pipe(remove_empty)\n     .pipe(lambda x: x.clean_names(case_type = \"upper\"))\n     .pipe(lambda x: x.rename(columns = {'SIZE_US_': 'SIZE_US', 'SIZE_EUROPE_':\"SIZE_EUROPE\", \"SIZE_UK_\":\"SIZE_UK\"}))\n     .pipe(lambda x: x.info())\n     )\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 14967 entries, 0 to 14966\nData columns (total 14 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   INVOICENO    14967 non-null  int64  \n 1   DATE         14967 non-null  object \n 2   COUNTRY      14967 non-null  object \n 3   PRODUCTID    14967 non-null  int64  \n 4   SHOP         14967 non-null  object \n 5   GENDER       14967 non-null  object \n 6   SIZE_US      14967 non-null  float64\n 7   SIZE_EUROPE  14967 non-null  object \n 8   SIZE_UK      14967 non-null  float64\n 9   UNITPRICE    14967 non-null  int64  \n 10  DISCOUNT     14967 non-null  float64\n 11  YEAR         14967 non-null  int64  \n 12  MONTH        14967 non-null  int64  \n 13  SALEPRICE    14967 non-null  float64\ndtypes: float64(4), int64(5), object(5)\nmemory usage: 1.6+ MB\n\n\n\n# Changing the names of the columns to uppercase\ndf_pd.rename(columns = str.upper, inplace = True)\ndf_pd.columns\n\nIndex(['INVOICENO', 'DATE', 'COUNTRY', 'PRODUCTID', 'SHOP', 'GENDER',\n       'SIZE (US)', 'SIZE (EUROPE)', 'SIZE (UK)', 'UNITPRICE', 'DISCOUNT',\n       'YEAR', 'MONTH', 'SALEPRICE'],\n      dtype='object')\n\n\n\nnew_column = df_pd.columns \\\n .str.replace(\"(\", '').str.replace(\")\", \"\") \\\n .str.replace(' ','_') # Cleaning the names of the variables\nnew_column\n\nIndex(['INVOICENO', 'DATE', 'COUNTRY', 'PRODUCTID', 'SHOP', 'GENDER',\n       'SIZE_US', 'SIZE_EUROPE', 'SIZE_UK', 'UNITPRICE', 'DISCOUNT', 'YEAR',\n       'MONTH', 'SALEPRICE'],\n      dtype='object')\n\n\n\ndf_pd.columns = new_column\ndf_pd.columns\n\nIndex(['INVOICENO', 'DATE', 'COUNTRY', 'PRODUCTID', 'SHOP', 'GENDER',\n       'SIZE_US', 'SIZE_EUROPE', 'SIZE_UK', 'UNITPRICE', 'DISCOUNT', 'YEAR',\n       'MONTH', 'SALEPRICE'],\n      dtype='object')\n\ndf_pd.rename(columns=str.upper, inplace = True)\ndf_pd.columns \n\nIndex(['INVOICENO', 'DATE', 'COUNTRY', 'PRODUCTID', 'SHOP', 'GENDER',\n       'SIZE_US', 'SIZE_EUROPE', 'SIZE_UK', 'UNITPRICE', 'DISCOUNT', 'YEAR',\n       'MONTH', 'SALEPRICE'],\n      dtype='object')\n\n\n\n\n\n\n3.7.1 Changing the Types of Variables\n\ndplyrpandas\n\n\n\ndf |&gt;\n    mutate (DATE = lubridate::mdy(DATE)) |&gt;\n    glimpse()\n\nRows: 14,967\nColumns: 14\n$ INVOICENO   &lt;dbl&gt; 52389, 52390, 52391, 52392, 52393, 52394, 52395, 52396, 52…\n$ DATE        &lt;date&gt; 2014-01-01, 2014-01-01, 2014-01-01, 2014-01-01, 2014-01-0…\n$ COUNTRY     &lt;chr&gt; \"United Kingdom\", \"United States\", \"Canada\", \"United State…\n$ PRODUCTID   &lt;dbl&gt; 2152, 2230, 2160, 2234, 2222, 2173, 2200, 2238, 2191, 2237…\n$ SHOP        &lt;chr&gt; \"UK2\", \"US15\", \"CAN7\", \"US6\", \"UK4\", \"US15\", \"GER2\", \"CAN5…\n$ GENDER      &lt;chr&gt; \"Male\", \"Male\", \"Male\", \"Female\", \"Female\", \"Male\", \"Femal…\n$ SIZE_US     &lt;dbl&gt; 11.0, 11.5, 9.5, 9.5, 9.0, 10.5, 9.0, 10.0, 10.5, 9.0, 10.…\n$ SIZE_EUROPE &lt;chr&gt; \"44\", \"44-45\", \"42-43\", \"40\", \"39-40\", \"43-44\", \"39-40\", \"…\n$ SIZE_UK     &lt;dbl&gt; 10.5, 11.0, 9.0, 7.5, 7.0, 10.0, 7.0, 9.5, 10.0, 7.0, 9.5,…\n$ UNITPRICE   &lt;dbl&gt; 159, 199, 149, 159, 159, 159, 179, 169, 139, 149, 129, 169…\n$ DISCOUNT    &lt;dbl&gt; 0.0, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1…\n$ YEAR        &lt;dbl&gt; 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014…\n$ MONTH       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ SALEPRICE   &lt;dbl&gt; 159.0, 159.2, 119.2, 159.0, 159.0, 159.0, 179.0, 169.0, 13…\n\n\n     From the above, it is now evident the the type of the DATE variable now is date.\n\ndf |&gt;\n    mutate (DATE = lubridate::mdy(DATE)) |&gt;\n    mutate (PRODUCTID = as.character(PRODUCTID)) |&gt;\n    glimpse()\n\nRows: 14,967\nColumns: 14\n$ INVOICENO   &lt;dbl&gt; 52389, 52390, 52391, 52392, 52393, 52394, 52395, 52396, 52…\n$ DATE        &lt;date&gt; 2014-01-01, 2014-01-01, 2014-01-01, 2014-01-01, 2014-01-0…\n$ COUNTRY     &lt;chr&gt; \"United Kingdom\", \"United States\", \"Canada\", \"United State…\n$ PRODUCTID   &lt;chr&gt; \"2152\", \"2230\", \"2160\", \"2234\", \"2222\", \"2173\", \"2200\", \"2…\n$ SHOP        &lt;chr&gt; \"UK2\", \"US15\", \"CAN7\", \"US6\", \"UK4\", \"US15\", \"GER2\", \"CAN5…\n$ GENDER      &lt;chr&gt; \"Male\", \"Male\", \"Male\", \"Female\", \"Female\", \"Male\", \"Femal…\n$ SIZE_US     &lt;dbl&gt; 11.0, 11.5, 9.5, 9.5, 9.0, 10.5, 9.0, 10.0, 10.5, 9.0, 10.…\n$ SIZE_EUROPE &lt;chr&gt; \"44\", \"44-45\", \"42-43\", \"40\", \"39-40\", \"43-44\", \"39-40\", \"…\n$ SIZE_UK     &lt;dbl&gt; 10.5, 11.0, 9.0, 7.5, 7.0, 10.0, 7.0, 9.5, 10.0, 7.0, 9.5,…\n$ UNITPRICE   &lt;dbl&gt; 159, 199, 149, 159, 159, 159, 179, 169, 139, 149, 129, 169…\n$ DISCOUNT    &lt;dbl&gt; 0.0, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1…\n$ YEAR        &lt;dbl&gt; 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014…\n$ MONTH       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ SALEPRICE   &lt;dbl&gt; 159.0, 159.2, 119.2, 159.0, 159.0, 159.0, 179.0, 169.0, 13…\n\n\n     From the above, it is now evident the the type of the DATE and PRODUCTID variable now is date (date) and character (chr) respectively. We can now incorparte the changes into the data frame.\n\ndf = df |&gt;\n    mutate (DATE = lubridate::mdy(DATE)) |&gt;\n    mutate (PRODUCTID = as.character(PRODUCTID)) \nglimpse(df)\n\nRows: 14,967\nColumns: 14\n$ INVOICENO   &lt;dbl&gt; 52389, 52390, 52391, 52392, 52393, 52394, 52395, 52396, 52…\n$ DATE        &lt;date&gt; 2014-01-01, 2014-01-01, 2014-01-01, 2014-01-01, 2014-01-0…\n$ COUNTRY     &lt;chr&gt; \"United Kingdom\", \"United States\", \"Canada\", \"United State…\n$ PRODUCTID   &lt;chr&gt; \"2152\", \"2230\", \"2160\", \"2234\", \"2222\", \"2173\", \"2200\", \"2…\n$ SHOP        &lt;chr&gt; \"UK2\", \"US15\", \"CAN7\", \"US6\", \"UK4\", \"US15\", \"GER2\", \"CAN5…\n$ GENDER      &lt;chr&gt; \"Male\", \"Male\", \"Male\", \"Female\", \"Female\", \"Male\", \"Femal…\n$ SIZE_US     &lt;dbl&gt; 11.0, 11.5, 9.5, 9.5, 9.0, 10.5, 9.0, 10.0, 10.5, 9.0, 10.…\n$ SIZE_EUROPE &lt;chr&gt; \"44\", \"44-45\", \"42-43\", \"40\", \"39-40\", \"43-44\", \"39-40\", \"…\n$ SIZE_UK     &lt;dbl&gt; 10.5, 11.0, 9.0, 7.5, 7.0, 10.0, 7.0, 9.5, 10.0, 7.0, 9.5,…\n$ UNITPRICE   &lt;dbl&gt; 159, 199, 149, 159, 159, 159, 179, 169, 139, 149, 129, 169…\n$ DISCOUNT    &lt;dbl&gt; 0.0, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1…\n$ YEAR        &lt;dbl&gt; 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014…\n$ MONTH       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ SALEPRICE   &lt;dbl&gt; 159.0, 159.2, 119.2, 159.0, 159.0, 159.0, 179.0, 169.0, 13…\n\n\n\n\n\n(\n    df_pd\n    .pipe(lambda x: x.assign(DATE = pd.to_datetime(x['DATE'])))\n    .pipe(lambda x: x.info())\n)\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 14967 entries, 0 to 14966\nData columns (total 14 columns):\n #   Column       Non-Null Count  Dtype         \n---  ------       --------------  -----         \n 0   INVOICENO    14967 non-null  int64         \n 1   DATE         14967 non-null  datetime64[ns]\n 2   COUNTRY      14967 non-null  object        \n 3   PRODUCTID    14967 non-null  int64         \n 4   SHOP         14967 non-null  object        \n 5   GENDER       14967 non-null  object        \n 6   SIZE_US      14967 non-null  float64       \n 7   SIZE_EUROPE  14967 non-null  object        \n 8   SIZE_UK      14967 non-null  float64       \n 9   UNITPRICE    14967 non-null  int64         \n 10  DISCOUNT     14967 non-null  float64       \n 11  YEAR         14967 non-null  int64         \n 12  MONTH        14967 non-null  int64         \n 13  SALEPRICE    14967 non-null  float64       \ndtypes: datetime64[ns](1), float64(4), int64(5), object(4)\nmemory usage: 1.6+ MB\n\n\n\n# converting integer to object\ndf_pd.INVOICENO = df_pd.INVOICENO.astype(str)\ndf_pd[['MONTH', 'PRODUCTID']] = df_pd[['MONTH', 'PRODUCTID']].astype(str)\ndf_pd.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 14967 entries, 0 to 14966\nData columns (total 14 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   INVOICENO    14967 non-null  object \n 1   DATE         14967 non-null  object \n 2   COUNTRY      14967 non-null  object \n 3   PRODUCTID    14967 non-null  object \n 4   SHOP         14967 non-null  object \n 5   GENDER       14967 non-null  object \n 6   SIZE_US      14967 non-null  float64\n 7   SIZE_EUROPE  14967 non-null  object \n 8   SIZE_UK      14967 non-null  float64\n 9   UNITPRICE    14967 non-null  int64  \n 10  DISCOUNT     14967 non-null  float64\n 11  YEAR         14967 non-null  int64  \n 12  MONTH        14967 non-null  object \n 13  SALEPRICE    14967 non-null  float64\ndtypes: float64(4), int64(2), object(8)\nmemory usage: 1.6+ MB",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Exploratory Data Analysis (EDA)</span>"
    ]
  },
  {
    "objectID": "eda.html#some-other-useful-functions",
    "href": "eda.html#some-other-useful-functions",
    "title": "3  Exploratory Data Analysis (EDA)",
    "section": "3.8 Some Other Useful Functions",
    "text": "3.8 Some Other Useful Functions\n     There are some other useful functions that can be used to explore the dataset for analysis. Some of those useful functions are discussed below.\n\ndplyrpandas\n\n\n\ndf|&gt; count(YEAR)\n\n# A tibble: 3 × 2\n   YEAR     n\n  &lt;dbl&gt; &lt;int&gt;\n1  2014  2753\n2  2015  4848\n3  2016  7366\n\n\n\ndf|&gt; count(COUNTRY)\n\n# A tibble: 4 × 2\n  COUNTRY            n\n  &lt;chr&gt;          &lt;int&gt;\n1 Canada          2952\n2 Germany         4392\n3 United Kingdom  1737\n4 United States   5886\n\n\n\ndf|&gt; distinct(COUNTRY)\n\n# A tibble: 4 × 1\n  COUNTRY       \n  &lt;chr&gt;         \n1 United Kingdom\n2 United States \n3 Canada        \n4 Germany       \n\n\n\n\n\ndf_pd['YEAR'].value_counts()\n\nYEAR\n2016    7366\n2015    4848\n2014    2753\nName: count, dtype: int64\n\n\n\ndf_pd['YEAR'].unique()\n\narray([2014, 2015, 2016])",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Exploratory Data Analysis (EDA)</span>"
    ]
  },
  {
    "objectID": "eda.html#six-verbs-for-eda",
    "href": "eda.html#six-verbs-for-eda",
    "title": "3  Exploratory Data Analysis (EDA)",
    "section": "3.9 Six Verbs for EDA",
    "text": "3.9 Six Verbs for EDA\n     Table 3.1 shows the comparable functions in both dplyr and pandas packages. These functions are very much important to perform exploratory data analysis in both R and Python. group_by (groupby in pandas) and summarize ()1 (agg () in pandas) are often used together; therefore, they are in the same group in Table 3.1.\n\n\n\n\nTable 3.1: Tidyverse and Pandas Equivalent Functions\n\n\n\n\n\n\n\nVerb Number\ntidyverse\npandas\n\n\n\n\n1\nfilter ()\nquery () or loc () or iloc ()\n\n\n2\narrange ()\nsort_values ()\n\n\n3\nselect ()\nfilter () or loc ()\n\n\n4\nrename ()\nrename ()\n\n\n5\nmutate ()\nassign ()\n\n\n6\ngroup_by ()\ngroupby ()\n\n\n6\nsummarize ()\nagg ()\n\n\n\n\n\n\n\n\n\n\n\n\n3.9.1 1st Verb - filter () Function\n     Filter functions are used to subset a data frame based on rows, meaning that retaining rows that satisfy given conditions. Filtering rows is also called slicing2 becasue we obtain a set of elements by filtering.\n\ndplyrpandas\n\n\n\ndf |&gt; filter (YEAR == \"2015\")\n\n# A tibble: 4,848 × 14\n   INVOICENO DATE       COUNTRY       PRODUCTID SHOP  GENDER SIZE_US SIZE_EUROPE\n       &lt;dbl&gt; &lt;date&gt;     &lt;chr&gt;         &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;      \n 1     54725 2015-01-01 United States 2187      US7   Male       9.5 42-43      \n 2     54726 2015-01-01 United States 2174      US3   Male       8.5 41-42      \n 3     54727 2015-01-01 United States 2240      US11  Male       9   42         \n 4     54728 2015-01-01 Germany       2220      GER2  Male      10   43         \n 5     54729 2015-01-01 United Kingd… 2199      UK5   Male       9.5 42-43      \n 6     54730 2015-01-01 Canada        2169      CAN7  Female     7   37-38      \n 7     54731 2015-01-01 Germany       2188      GER1  Female     9.5 40         \n 8     54732 2015-01-02 United Kingd… 2155      UK5   Female    10   40-41      \n 9     54733 2015-01-02 United States 2173      US5   Female     9   39-40      \n10     54734 2015-01-02 Germany       2222      GER3  Female     7.5 38         \n# ℹ 4,838 more rows\n# ℹ 6 more variables: SIZE_UK &lt;dbl&gt;, UNITPRICE &lt;dbl&gt;, DISCOUNT &lt;dbl&gt;,\n#   YEAR &lt;dbl&gt;, MONTH &lt;dbl&gt;, SALEPRICE &lt;dbl&gt;\n\n\n\ndf |&gt; filter (COUNTRY %in% c(\"United States\", \"Canada\"))\n\n# A tibble: 8,838 × 14\n   INVOICENO DATE       COUNTRY       PRODUCTID SHOP  GENDER SIZE_US SIZE_EUROPE\n       &lt;dbl&gt; &lt;date&gt;     &lt;chr&gt;         &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;      \n 1     52390 2014-01-01 United States 2230      US15  Male      11.5 44-45      \n 2     52391 2014-01-01 Canada        2160      CAN7  Male       9.5 42-43      \n 3     52392 2014-01-01 United States 2234      US6   Female     9.5 40         \n 4     52394 2014-01-01 United States 2173      US15  Male      10.5 43-44      \n 5     52396 2014-01-02 Canada        2238      CAN5  Male      10   43         \n 6     52397 2014-01-02 United States 2191      US13  Male      10.5 43-44      \n 7     52399 2014-01-02 United States 2197      US1   Male      10   43         \n 8     52399 2014-01-02 United States 2213      US11  Female     9.5 40         \n 9     52399 2014-01-02 United States 2206      US2   Female     9.5 40         \n10     52400 2014-01-02 United States 2152      US15  Male       8   41         \n# ℹ 8,828 more rows\n# ℹ 6 more variables: SIZE_UK &lt;dbl&gt;, UNITPRICE &lt;dbl&gt;, DISCOUNT &lt;dbl&gt;,\n#   YEAR &lt;dbl&gt;, MONTH &lt;dbl&gt;, SALEPRICE &lt;dbl&gt;\n\n\n\ndf |&gt; filter (COUNTRY == \"United States\", YEAR == \"2016\")\n\n# A tibble: 2,935 × 14\n   INVOICENO DATE       COUNTRY       PRODUCTID SHOP  GENDER SIZE_US SIZE_EUROPE\n       &lt;dbl&gt; &lt;date&gt;     &lt;chr&gt;         &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;      \n 1     59206 2016-01-02 United States 2186      US13  Female     8   38-39      \n 2     59209 2016-01-02 United States 2193      US14  Female     9   39-40      \n 3     59213 2016-01-02 United States 2228      US13  Male       9.5 42-43      \n 4     59214 2016-01-02 United States 2177      US12  Female    10.5 41         \n 5     59214 2016-01-02 United States 2236      US6   Male       8.5 41-42      \n 6     59219 2016-01-03 United States 2188      US14  Female     9.5 40         \n 7     59221 2016-01-03 United States 2178      US13  Female     8   38-39      \n 8     59223 2016-01-03 United States 2158      US3   Male       8   41         \n 9     59225 2016-01-03 United States 2236      US13  Male       8   41         \n10     59226 2016-01-03 United States 2207      US14  Male      14   47         \n# ℹ 2,925 more rows\n# ℹ 6 more variables: SIZE_UK &lt;dbl&gt;, UNITPRICE &lt;dbl&gt;, DISCOUNT &lt;dbl&gt;,\n#   YEAR &lt;dbl&gt;, MONTH &lt;dbl&gt;, SALEPRICE &lt;dbl&gt;\n\n\n\ndf |&gt; filter (COUNTRY == \"United States\", YEAR %in% c(\"2015\",\"2016\"))\n\n# A tibble: 4,859 × 14\n   INVOICENO DATE       COUNTRY       PRODUCTID SHOP  GENDER SIZE_US SIZE_EUROPE\n       &lt;dbl&gt; &lt;date&gt;     &lt;chr&gt;         &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;      \n 1     54725 2015-01-01 United States 2187      US7   Male       9.5 42-43      \n 2     54726 2015-01-01 United States 2174      US3   Male       8.5 41-42      \n 3     54727 2015-01-01 United States 2240      US11  Male       9   42         \n 4     54733 2015-01-02 United States 2173      US5   Female     9   39-40      \n 5     54738 2015-01-02 United States 2226      US3   Male      10   43         \n 6     54739 2015-01-02 United States 2199      US11  Male       9.5 42-43      \n 7     54742 2015-01-03 United States 2209      US6   Male      10   43         \n 8     54743 2015-01-03 United States 2238      US15  Female     7.5 38         \n 9     54745 2015-01-04 United States 2214      US12  Male      10.5 43-44      \n10     54749 2015-01-04 United States 2162      US15  Male       9.5 42-43      \n# ℹ 4,849 more rows\n# ℹ 6 more variables: SIZE_UK &lt;dbl&gt;, UNITPRICE &lt;dbl&gt;, DISCOUNT &lt;dbl&gt;,\n#   YEAR &lt;dbl&gt;, MONTH &lt;dbl&gt;, SALEPRICE &lt;dbl&gt;\n\n\n\ndf |&gt; filter (COUNTRY %in% c(\"United States\", \"Canada\"), YEAR == \"2014\")\n\n# A tibble: 1,649 × 14\n   INVOICENO DATE       COUNTRY       PRODUCTID SHOP  GENDER SIZE_US SIZE_EUROPE\n       &lt;dbl&gt; &lt;date&gt;     &lt;chr&gt;         &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;      \n 1     52390 2014-01-01 United States 2230      US15  Male      11.5 44-45      \n 2     52391 2014-01-01 Canada        2160      CAN7  Male       9.5 42-43      \n 3     52392 2014-01-01 United States 2234      US6   Female     9.5 40         \n 4     52394 2014-01-01 United States 2173      US15  Male      10.5 43-44      \n 5     52396 2014-01-02 Canada        2238      CAN5  Male      10   43         \n 6     52397 2014-01-02 United States 2191      US13  Male      10.5 43-44      \n 7     52399 2014-01-02 United States 2197      US1   Male      10   43         \n 8     52399 2014-01-02 United States 2213      US11  Female     9.5 40         \n 9     52399 2014-01-02 United States 2206      US2   Female     9.5 40         \n10     52400 2014-01-02 United States 2152      US15  Male       8   41         \n# ℹ 1,639 more rows\n# ℹ 6 more variables: SIZE_UK &lt;dbl&gt;, UNITPRICE &lt;dbl&gt;, DISCOUNT &lt;dbl&gt;,\n#   YEAR &lt;dbl&gt;, MONTH &lt;dbl&gt;, SALEPRICE &lt;dbl&gt;\n\n\n\n\n\ndf_pd.query(\"YEAR == 2015\")\n\n     INVOICENO        DATE         COUNTRY  ...  YEAR MONTH SALEPRICE\n2753     54725    1/1/2015   United States  ...  2015     1     179.0\n2754     54726    1/1/2015   United States  ...  2015     1     169.0\n2755     54727    1/1/2015   United States  ...  2015     1     116.1\n2756     54728    1/1/2015         Germany  ...  2015     1     129.0\n2757     54729    1/1/2015  United Kingdom  ...  2015     1     139.0\n...        ...         ...             ...  ...   ...   ...       ...\n7596     59192  12/31/2015   United States  ...  2015    12      79.5\n7597     59193  12/31/2015   United States  ...  2015    12     139.0\n7598     59194  12/31/2015         Germany  ...  2015    12     159.0\n7599     59195  12/31/2015         Germany  ...  2015    12     149.0\n7600     59196  12/31/2015   United States  ...  2015    12     179.0\n\n[4848 rows x 14 columns]\n\n\n\ndf_pd.query('COUNTRY== \"United States\" | COUNTRY == \"Canada\"')\n\n      INVOICENO        DATE        COUNTRY  ...  YEAR MONTH SALEPRICE\n1         52390    1/1/2014  United States  ...  2014     1     159.2\n2         52391    1/1/2014         Canada  ...  2014     1     119.2\n3         52392    1/1/2014  United States  ...  2014     1     159.0\n5         52394    1/1/2014  United States  ...  2014     1     159.0\n7         52396    1/2/2014         Canada  ...  2014     1     169.0\n...         ...         ...            ...  ...   ...   ...       ...\n14959     65770  12/31/2016  United States  ...  2016    12     119.2\n14960     65771  12/31/2016  United States  ...  2016    12     189.0\n14961     65772  12/31/2016  United States  ...  2016    12     129.0\n14963     65774  12/31/2016  United States  ...  2016    12     149.0\n14964     65775  12/31/2016         Canada  ...  2016    12     125.3\n\n[8838 rows x 14 columns]\n\n\n\ndf_pd.query(\"COUNTRY in ['United States', 'Canada']\")\n\n      INVOICENO        DATE        COUNTRY  ...  YEAR MONTH SALEPRICE\n1         52390    1/1/2014  United States  ...  2014     1     159.2\n2         52391    1/1/2014         Canada  ...  2014     1     119.2\n3         52392    1/1/2014  United States  ...  2014     1     159.0\n5         52394    1/1/2014  United States  ...  2014     1     159.0\n7         52396    1/2/2014         Canada  ...  2014     1     169.0\n...         ...         ...            ...  ...   ...   ...       ...\n14959     65770  12/31/2016  United States  ...  2016    12     119.2\n14960     65771  12/31/2016  United States  ...  2016    12     189.0\n14961     65772  12/31/2016  United States  ...  2016    12     129.0\n14963     65774  12/31/2016  United States  ...  2016    12     149.0\n14964     65775  12/31/2016         Canada  ...  2016    12     125.3\n\n[8838 rows x 14 columns]\n\n\n\ndf_pd.query(\"COUNTRY== 'United States' & YEAR== 2016\")\n\n      INVOICENO        DATE        COUNTRY  ...  YEAR MONTH SALEPRICE\n7610      59206    1/2/2016  United States  ...  2016     1     132.3\n7613      59209    1/2/2016  United States  ...  2016     1     127.2\n7617      59213    1/2/2016  United States  ...  2016     1     125.3\n7618      59214    1/2/2016  United States  ...  2016     1     151.2\n7619      59214    1/2/2016  United States  ...  2016     1     151.2\n...         ...         ...            ...  ...   ...   ...       ...\n14956     65767  12/31/2016  United States  ...  2016    12     139.0\n14959     65770  12/31/2016  United States  ...  2016    12     119.2\n14960     65771  12/31/2016  United States  ...  2016    12     189.0\n14961     65772  12/31/2016  United States  ...  2016    12     129.0\n14963     65774  12/31/2016  United States  ...  2016    12     149.0\n\n[2935 rows x 14 columns]\n\n\n\ndf_pd.query(\"COUNTRY== 'United States' & YEAR in [2015,2016]\")\n\n      INVOICENO        DATE        COUNTRY  ...  YEAR MONTH SALEPRICE\n2753      54725    1/1/2015  United States  ...  2015     1     179.0\n2754      54726    1/1/2015  United States  ...  2015     1     169.0\n2755      54727    1/1/2015  United States  ...  2015     1     116.1\n2761      54733    1/2/2015  United States  ...  2015     1     179.0\n2766      54738    1/2/2015  United States  ...  2015     1     199.0\n...         ...         ...            ...  ...   ...   ...       ...\n14956     65767  12/31/2016  United States  ...  2016    12     139.0\n14959     65770  12/31/2016  United States  ...  2016    12     119.2\n14960     65771  12/31/2016  United States  ...  2016    12     189.0\n14961     65772  12/31/2016  United States  ...  2016    12     129.0\n14963     65774  12/31/2016  United States  ...  2016    12     149.0\n\n[4859 rows x 14 columns]\n\n\n\ndf_pd[df_pd['COUNTRY'] == \"United States\"]\n\n      INVOICENO        DATE        COUNTRY  ...  YEAR MONTH SALEPRICE\n1         52390    1/1/2014  United States  ...  2014     1     159.2\n3         52392    1/1/2014  United States  ...  2014     1     159.0\n5         52394    1/1/2014  United States  ...  2014     1     159.0\n8         52397    1/2/2014  United States  ...  2014     1     139.0\n10        52399    1/2/2014  United States  ...  2014     1     129.0\n...         ...         ...            ...  ...   ...   ...       ...\n14956     65767  12/31/2016  United States  ...  2016    12     139.0\n14959     65770  12/31/2016  United States  ...  2016    12     119.2\n14960     65771  12/31/2016  United States  ...  2016    12     189.0\n14961     65772  12/31/2016  United States  ...  2016    12     129.0\n14963     65774  12/31/2016  United States  ...  2016    12     149.0\n\n[5886 rows x 14 columns]\n\n\n\ndf_pd.loc[(df_pd['COUNTRY']==\"United States\")]\n\n      INVOICENO        DATE        COUNTRY  ...  YEAR MONTH SALEPRICE\n1         52390    1/1/2014  United States  ...  2014     1     159.2\n3         52392    1/1/2014  United States  ...  2014     1     159.0\n5         52394    1/1/2014  United States  ...  2014     1     159.0\n8         52397    1/2/2014  United States  ...  2014     1     139.0\n10        52399    1/2/2014  United States  ...  2014     1     129.0\n...         ...         ...            ...  ...   ...   ...       ...\n14956     65767  12/31/2016  United States  ...  2016    12     139.0\n14959     65770  12/31/2016  United States  ...  2016    12     119.2\n14960     65771  12/31/2016  United States  ...  2016    12     189.0\n14961     65772  12/31/2016  United States  ...  2016    12     129.0\n14963     65774  12/31/2016  United States  ...  2016    12     149.0\n\n[5886 rows x 14 columns]\n\n\n\ndf_pd.loc[df_pd['COUNTRY'].isin([\"United States\", \"Canada\"])]\n\n      INVOICENO        DATE        COUNTRY  ...  YEAR MONTH SALEPRICE\n1         52390    1/1/2014  United States  ...  2014     1     159.2\n2         52391    1/1/2014         Canada  ...  2014     1     119.2\n3         52392    1/1/2014  United States  ...  2014     1     159.0\n5         52394    1/1/2014  United States  ...  2014     1     159.0\n7         52396    1/2/2014         Canada  ...  2014     1     169.0\n...         ...         ...            ...  ...   ...   ...       ...\n14959     65770  12/31/2016  United States  ...  2016    12     119.2\n14960     65771  12/31/2016  United States  ...  2016    12     189.0\n14961     65772  12/31/2016  United States  ...  2016    12     129.0\n14963     65774  12/31/2016  United States  ...  2016    12     149.0\n14964     65775  12/31/2016         Canada  ...  2016    12     125.3\n\n[8838 rows x 14 columns]\n\n\n\ndf_pd.loc[df_pd['COUNTRY']\\\n .isin([\"United States\", \"Canada\"]) &(df_pd['YEAR']==2014)]\n\n     INVOICENO        DATE        COUNTRY  ...  YEAR MONTH SALEPRICE\n1        52390    1/1/2014  United States  ...  2014     1     159.2\n2        52391    1/1/2014         Canada  ...  2014     1     119.2\n3        52392    1/1/2014  United States  ...  2014     1     159.0\n5        52394    1/1/2014  United States  ...  2014     1     159.0\n7        52396    1/2/2014         Canada  ...  2014     1     169.0\n...        ...         ...            ...  ...   ...   ...       ...\n2739     54713  12/30/2014  United States  ...  2014    12     189.0\n2745     54718  12/31/2014         Canada  ...  2014    12     151.2\n2746     54719  12/31/2014  United States  ...  2014    12     199.0\n2748     54721  12/31/2014         Canada  ...  2014    12      74.5\n2749     54722  12/31/2014  United States  ...  2014    12     118.3\n\n[1649 rows x 14 columns]\n\n\n\ndf_pd.loc[(df_pd['COUNTRY']==\"United States\") &(df_pd [\"YEAR\"] ==2014)]\n\n     INVOICENO        DATE        COUNTRY  ...  YEAR MONTH SALEPRICE\n1        52390    1/1/2014  United States  ...  2014     1     159.2\n3        52392    1/1/2014  United States  ...  2014     1     159.0\n5        52394    1/1/2014  United States  ...  2014     1     159.0\n8        52397    1/2/2014  United States  ...  2014     1     139.0\n10       52399    1/2/2014  United States  ...  2014     1     129.0\n...        ...         ...            ...  ...   ...   ...       ...\n2731     54705  12/29/2014  United States  ...  2014    12     179.0\n2734     54708  12/30/2014  United States  ...  2014    12     159.0\n2739     54713  12/30/2014  United States  ...  2014    12     189.0\n2746     54719  12/31/2014  United States  ...  2014    12     199.0\n2749     54722  12/31/2014  United States  ...  2014    12     118.3\n\n[1027 rows x 14 columns]\n\n\n\ndf_pd.loc[df_pd['COUNTRY'] == \"United States\", :]\n\n      INVOICENO        DATE        COUNTRY  ...  YEAR MONTH SALEPRICE\n1         52390    1/1/2014  United States  ...  2014     1     159.2\n3         52392    1/1/2014  United States  ...  2014     1     159.0\n5         52394    1/1/2014  United States  ...  2014     1     159.0\n8         52397    1/2/2014  United States  ...  2014     1     139.0\n10        52399    1/2/2014  United States  ...  2014     1     129.0\n...         ...         ...            ...  ...   ...   ...       ...\n14956     65767  12/31/2016  United States  ...  2016    12     139.0\n14959     65770  12/31/2016  United States  ...  2016    12     119.2\n14960     65771  12/31/2016  United States  ...  2016    12     189.0\n14961     65772  12/31/2016  United States  ...  2016    12     129.0\n14963     65774  12/31/2016  United States  ...  2016    12     149.0\n\n[5886 rows x 14 columns]\n\n\n\ndf_pd.loc[\n    df_pd['COUNTRY']=='United States',\n    ['COUNTRY', \"UNITPRICE\", \"SALEPRICE\"]]\n\n             COUNTRY  UNITPRICE  SALEPRICE\n1      United States        199      159.2\n3      United States        159      159.0\n5      United States        159      159.0\n8      United States        139      139.0\n10     United States        129      129.0\n...              ...        ...        ...\n14956  United States        139      139.0\n14959  United States        149      119.2\n14960  United States        189      189.0\n14961  United States        129      129.0\n14963  United States        149      149.0\n\n[5886 rows x 3 columns]\n\n\n\n\n\n\n\n3.9.2 2nd Verb - arrange () Function\n     In arrange functions, we order the rows of a data frame by the values of given columns. It is like sorting or odering the data.\n\ndplyrpandas\n\n\n\ndf |&gt;\n    arrange(DATE)     \n\n# A tibble: 14,967 × 14\n   INVOICENO DATE       COUNTRY       PRODUCTID SHOP  GENDER SIZE_US SIZE_EUROPE\n       &lt;dbl&gt; &lt;date&gt;     &lt;chr&gt;         &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;      \n 1     52389 2014-01-01 United Kingd… 2152      UK2   Male      11   44         \n 2     52390 2014-01-01 United States 2230      US15  Male      11.5 44-45      \n 3     52391 2014-01-01 Canada        2160      CAN7  Male       9.5 42-43      \n 4     52392 2014-01-01 United States 2234      US6   Female     9.5 40         \n 5     52393 2014-01-01 United Kingd… 2222      UK4   Female     9   39-40      \n 6     52394 2014-01-01 United States 2173      US15  Male      10.5 43-44      \n 7     52395 2014-01-02 Germany       2200      GER2  Female     9   39-40      \n 8     52396 2014-01-02 Canada        2238      CAN5  Male      10   43         \n 9     52397 2014-01-02 United States 2191      US13  Male      10.5 43-44      \n10     52398 2014-01-02 United Kingd… 2237      UK1   Female     9   39-40      \n# ℹ 14,957 more rows\n# ℹ 6 more variables: SIZE_UK &lt;dbl&gt;, UNITPRICE &lt;dbl&gt;, DISCOUNT &lt;dbl&gt;,\n#   YEAR &lt;dbl&gt;, MONTH &lt;dbl&gt;, SALEPRICE &lt;dbl&gt;\n\n\n\ndf |&gt;\n    arrange(desc(DATE))     \n\n# A tibble: 14,967 × 14\n   INVOICENO DATE       COUNTRY       PRODUCTID SHOP  GENDER SIZE_US SIZE_EUROPE\n       &lt;dbl&gt; &lt;date&gt;     &lt;chr&gt;         &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;      \n 1     65765 2016-12-31 Canada        2199      CAN5  Male      11   44         \n 2     65766 2016-12-31 United Kingd… 2202      UK1   Male       9.5 42-43      \n 3     65767 2016-12-31 United States 2147      US15  Male       9.5 42-43      \n 4     65768 2016-12-31 Germany       2205      GER1  Female     7.5 38         \n 5     65769 2016-12-31 Germany       2210      GER2  Male      10.5 43-44      \n 6     65770 2016-12-31 United States 2178      US13  Female     8   38-39      \n 7     65771 2016-12-31 United States 2209      US15  Male       9   42         \n 8     65772 2016-12-31 United States 2168      US13  Male       8   41         \n 9     65773 2016-12-31 United Kingd… 2154      UK2   Male       9.5 42-43      \n10     65774 2016-12-31 United States 2181      US12  Female    12   42-43      \n# ℹ 14,957 more rows\n# ℹ 6 more variables: SIZE_UK &lt;dbl&gt;, UNITPRICE &lt;dbl&gt;, DISCOUNT &lt;dbl&gt;,\n#   YEAR &lt;dbl&gt;, MONTH &lt;dbl&gt;, SALEPRICE &lt;dbl&gt;\n\n\n\ndf |&gt;\n    arrange(MONTH, SALEPRICE)     \n\n# A tibble: 14,967 × 14\n   INVOICENO DATE       COUNTRY       PRODUCTID SHOP  GENDER SIZE_US SIZE_EUROPE\n       &lt;dbl&gt; &lt;date&gt;     &lt;chr&gt;         &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;      \n 1     52414 2014-01-05 Germany       2239      GER2  Female     8.5 39         \n 2     52533 2014-01-25 Canada        2151      CAN5  Female     9   39-40      \n 3     52539 2014-01-26 United Kingd… 2227      UK1   Female     7.5 38         \n 4     52548 2014-01-27 United Kingd… 2224      UK3   Male       8.5 41-42      \n 5     54734 2015-01-02 Germany       2222      GER3  Female     7.5 38         \n 6     54772 2015-01-06 Germany       2159      GER1  Male      12   45         \n 7     54864 2015-01-16 Germany       2239      GER2  Female     7.5 38         \n 8     54989 2015-01-28 Canada        2152      CAN6  Female     8   38-39      \n 9     59220 2016-01-03 Canada        2202      CAN7  Male      10.5 43-44      \n10     59242 2016-01-04 United States 2231      US9   Female     9   39-40      \n# ℹ 14,957 more rows\n# ℹ 6 more variables: SIZE_UK &lt;dbl&gt;, UNITPRICE &lt;dbl&gt;, DISCOUNT &lt;dbl&gt;,\n#   YEAR &lt;dbl&gt;, MONTH &lt;dbl&gt;, SALEPRICE &lt;dbl&gt;\n\n\n\n\n\ndf_pd.sort_values(by =['DATE'])   \n\n      INVOICENO      DATE         COUNTRY  ...  YEAR MONTH SALEPRICE\n0         52389  1/1/2014  United Kingdom  ...  2014     1     159.0\n1         52390  1/1/2014   United States  ...  2014     1     159.2\n2         52391  1/1/2014          Canada  ...  2014     1     119.2\n3         52392  1/1/2014   United States  ...  2014     1     159.0\n4         52393  1/1/2014  United Kingdom  ...  2014     1     159.0\n...         ...       ...             ...  ...   ...   ...       ...\n12785     63807  9/9/2016         Germany  ...  2016     9     189.0\n12786     63808  9/9/2016         Germany  ...  2016     9     129.0\n12787     63809  9/9/2016   United States  ...  2016     9     179.0\n12789     63811  9/9/2016   United States  ...  2016     9     125.3\n12779     63802  9/9/2016   United States  ...  2016     9     125.1\n\n[14967 rows x 14 columns]\n\n\n\ndf_pd.sort_values(by =['DATE'], ascending = False)   \n\n      INVOICENO      DATE         COUNTRY  ...  YEAR MONTH SALEPRICE\n12778     63802  9/9/2016   United States  ...  2016     9     139.0\n12784     63806  9/9/2016         Germany  ...  2016     9     139.0\n12773     63797  9/9/2016         Germany  ...  2016     9      90.3\n12772     63796  9/9/2016         Germany  ...  2016     9     111.3\n12771     63795  9/9/2016         Germany  ...  2016     9     152.1\n...         ...       ...             ...  ...   ...   ...       ...\n5         52394  1/1/2014   United States  ...  2014     1     159.0\n4         52393  1/1/2014  United Kingdom  ...  2014     1     159.0\n3         52392  1/1/2014   United States  ...  2014     1     159.0\n2         52391  1/1/2014          Canada  ...  2014     1     119.2\n0         52389  1/1/2014  United Kingdom  ...  2014     1     159.0\n\n[14967 rows x 14 columns]\n\n\n\ndf_pd.sort_values(by =['MONTH', 'SALEPRICE'])\n\n      INVOICENO       DATE         COUNTRY  ...  YEAR MONTH SALEPRICE\n33        52414   1/5/2014         Germany  ...  2014     1      64.5\n177       52533  1/25/2014          Canada  ...  2014     1      64.5\n185       52539  1/26/2014  United Kingdom  ...  2014     1      64.5\n194       52548  1/27/2014  United Kingdom  ...  2014     1      64.5\n2762      54734   1/2/2015         Germany  ...  2015     1      64.5\n...         ...        ...             ...  ...   ...   ...       ...\n13245     64219  9/29/2016  United Kingdom  ...  2016     9     199.0\n13246     64220  9/29/2016   United States  ...  2016     9     199.0\n13248     64222  9/29/2016   United States  ...  2016     9     199.0\n13251     64224  9/29/2016         Germany  ...  2016     9     199.0\n13272     64244  9/30/2016   United States  ...  2016     9     199.0\n\n[14967 rows x 14 columns]\n\n\n\n\n\n\n\n3.9.3 3rd Verb - select () Function\n     Select functions help to select or obtain columns from the data frame. When there are a lot of columns in our dataset, select functions become very useful.\n\ndplyrpandas\n\n\n\ndf |&gt; select(DATE, UNITPRICE, DISCOUNT)   \n\n# A tibble: 14,967 × 3\n   DATE       UNITPRICE DISCOUNT\n   &lt;date&gt;         &lt;dbl&gt;    &lt;dbl&gt;\n 1 2014-01-01       159      0  \n 2 2014-01-01       199      0.2\n 3 2014-01-01       149      0.2\n 4 2014-01-01       159      0  \n 5 2014-01-01       159      0  \n 6 2014-01-01       159      0  \n 7 2014-01-02       179      0  \n 8 2014-01-02       169      0  \n 9 2014-01-02       139      0  \n10 2014-01-02       149      0  \n# ℹ 14,957 more rows\n\n\n\ndf |&gt; select(1:2, 5:8)  \n\n# A tibble: 14,967 × 6\n   INVOICENO DATE       SHOP  GENDER SIZE_US SIZE_EUROPE\n       &lt;dbl&gt; &lt;date&gt;     &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;      \n 1     52389 2014-01-01 UK2   Male      11   44         \n 2     52390 2014-01-01 US15  Male      11.5 44-45      \n 3     52391 2014-01-01 CAN7  Male       9.5 42-43      \n 4     52392 2014-01-01 US6   Female     9.5 40         \n 5     52393 2014-01-01 UK4   Female     9   39-40      \n 6     52394 2014-01-01 US15  Male      10.5 43-44      \n 7     52395 2014-01-02 GER2  Female     9   39-40      \n 8     52396 2014-01-02 CAN5  Male      10   43         \n 9     52397 2014-01-02 US13  Male      10.5 43-44      \n10     52398 2014-01-02 UK1   Female     9   39-40      \n# ℹ 14,957 more rows\n\n\n\ndf |&gt;\n    select(starts_with('SIZE'))\n\n# A tibble: 14,967 × 3\n   SIZE_US SIZE_EUROPE SIZE_UK\n     &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt;\n 1    11   44             10.5\n 2    11.5 44-45          11  \n 3     9.5 42-43           9  \n 4     9.5 40              7.5\n 5     9   39-40           7  \n 6    10.5 43-44          10  \n 7     9   39-40           7  \n 8    10   43              9.5\n 9    10.5 43-44          10  \n10     9   39-40           7  \n# ℹ 14,957 more rows\n\n\n\ndf |&gt;\n    select(ends_with('PRICE'))\n\n# A tibble: 14,967 × 2\n   UNITPRICE SALEPRICE\n       &lt;dbl&gt;     &lt;dbl&gt;\n 1       159      159 \n 2       199      159.\n 3       149      119.\n 4       159      159 \n 5       159      159 \n 6       159      159 \n 7       179      179 \n 8       169      169 \n 9       139      139 \n10       149      149 \n# ℹ 14,957 more rows\n\n\n\ndf |&gt;\n    select(contains(\"_\"))\n\n# A tibble: 14,967 × 3\n   SIZE_US SIZE_EUROPE SIZE_UK\n     &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt;\n 1    11   44             10.5\n 2    11.5 44-45          11  \n 3     9.5 42-43           9  \n 4     9.5 40              7.5\n 5     9   39-40           7  \n 6    10.5 43-44          10  \n 7     9   39-40           7  \n 8    10   43              9.5\n 9    10.5 43-44          10  \n10     9   39-40           7  \n# ℹ 14,957 more rows\n\n\n\ndf |&gt;\n    select(matches(\"SIZE\"))\n\n# A tibble: 14,967 × 3\n   SIZE_US SIZE_EUROPE SIZE_UK\n     &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt;\n 1    11   44             10.5\n 2    11.5 44-45          11  \n 3     9.5 42-43           9  \n 4     9.5 40              7.5\n 5     9   39-40           7  \n 6    10.5 43-44          10  \n 7     9   39-40           7  \n 8    10   43              9.5\n 9    10.5 43-44          10  \n10     9   39-40           7  \n# ℹ 14,957 more rows\n\n\n\ndf |&gt;\n    select(matches(\"PRICE$\"))\n\n# A tibble: 14,967 × 2\n   UNITPRICE SALEPRICE\n       &lt;dbl&gt;     &lt;dbl&gt;\n 1       159      159 \n 2       199      159.\n 3       149      119.\n 4       159      159 \n 5       159      159 \n 6       159      159 \n 7       179      179 \n 8       169      169 \n 9       139      139 \n10       149      149 \n# ℹ 14,957 more rows\n\n\n\n# starts with letter S\ndf |&gt;\n    select(matches(\"^S\"))\n\n# A tibble: 14,967 × 5\n   SHOP  SIZE_US SIZE_EUROPE SIZE_UK SALEPRICE\n   &lt;chr&gt;   &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt;     &lt;dbl&gt;\n 1 UK2      11   44             10.5      159 \n 2 US15     11.5 44-45          11        159.\n 3 CAN7      9.5 42-43           9        119.\n 4 US6       9.5 40              7.5      159 \n 5 UK4       9   39-40           7        159 \n 6 US15     10.5 43-44          10        159 \n 7 GER2      9   39-40           7        179 \n 8 CAN5     10   43              9.5      169 \n 9 US13     10.5 43-44          10        139 \n10 UK1       9   39-40           7        149 \n# ℹ 14,957 more rows\n\n\n\ndf |&gt;\n    select(where(is.character))\n\n# A tibble: 14,967 × 5\n   COUNTRY        PRODUCTID SHOP  GENDER SIZE_EUROPE\n   &lt;chr&gt;          &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;  &lt;chr&gt;      \n 1 United Kingdom 2152      UK2   Male   44         \n 2 United States  2230      US15  Male   44-45      \n 3 Canada         2160      CAN7  Male   42-43      \n 4 United States  2234      US6   Female 40         \n 5 United Kingdom 2222      UK4   Female 39-40      \n 6 United States  2173      US15  Male   43-44      \n 7 Germany        2200      GER2  Female 39-40      \n 8 Canada         2238      CAN5  Male   43         \n 9 United States  2191      US13  Male   43-44      \n10 United Kingdom 2237      UK1   Female 39-40      \n# ℹ 14,957 more rows\n\n\n\ndf |&gt;\n    select(where(is.numeric))\n\n# A tibble: 14,967 × 8\n   INVOICENO SIZE_US SIZE_UK UNITPRICE DISCOUNT  YEAR MONTH SALEPRICE\n       &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;\n 1     52389    11      10.5       159      0    2014     1      159 \n 2     52390    11.5    11         199      0.2  2014     1      159.\n 3     52391     9.5     9         149      0.2  2014     1      119.\n 4     52392     9.5     7.5       159      0    2014     1      159 \n 5     52393     9       7         159      0    2014     1      159 \n 6     52394    10.5    10         159      0    2014     1      159 \n 7     52395     9       7         179      0    2014     1      179 \n 8     52396    10       9.5       169      0    2014     1      169 \n 9     52397    10.5    10         139      0    2014     1      139 \n10     52398     9       7         149      0    2014     1      149 \n# ℹ 14,957 more rows\n\n\n\ndf |&gt;\n    select(MONTH, YEAR, everything())\n\n# A tibble: 14,967 × 14\n   MONTH  YEAR INVOICENO DATE       COUNTRY       PRODUCTID SHOP  GENDER SIZE_US\n   &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt; &lt;date&gt;     &lt;chr&gt;         &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt;\n 1     1  2014     52389 2014-01-01 United Kingd… 2152      UK2   Male      11  \n 2     1  2014     52390 2014-01-01 United States 2230      US15  Male      11.5\n 3     1  2014     52391 2014-01-01 Canada        2160      CAN7  Male       9.5\n 4     1  2014     52392 2014-01-01 United States 2234      US6   Female     9.5\n 5     1  2014     52393 2014-01-01 United Kingd… 2222      UK4   Female     9  \n 6     1  2014     52394 2014-01-01 United States 2173      US15  Male      10.5\n 7     1  2014     52395 2014-01-02 Germany       2200      GER2  Female     9  \n 8     1  2014     52396 2014-01-02 Canada        2238      CAN5  Male      10  \n 9     1  2014     52397 2014-01-02 United States 2191      US13  Male      10.5\n10     1  2014     52398 2014-01-02 United Kingd… 2237      UK1   Female     9  \n# ℹ 14,957 more rows\n# ℹ 5 more variables: SIZE_EUROPE &lt;chr&gt;, SIZE_UK &lt;dbl&gt;, UNITPRICE &lt;dbl&gt;,\n#   DISCOUNT &lt;dbl&gt;, SALEPRICE &lt;dbl&gt;\n\n\n\n# any_of () vs all_of ()\ndf |&gt;\n    select(any_of(c(\"PRICE\", \"SIZE\")))\n\n# A tibble: 14,967 × 0\n\n\n\n# Dropping columns \ndf |&gt;\n    select(-DATE)\n\n# A tibble: 14,967 × 13\n   INVOICENO COUNTRY        PRODUCTID SHOP  GENDER SIZE_US SIZE_EUROPE SIZE_UK\n       &lt;dbl&gt; &lt;chr&gt;          &lt;chr&gt;     &lt;chr&gt; &lt;chr&gt;    &lt;dbl&gt; &lt;chr&gt;         &lt;dbl&gt;\n 1     52389 United Kingdom 2152      UK2   Male      11   44             10.5\n 2     52390 United States  2230      US15  Male      11.5 44-45          11  \n 3     52391 Canada         2160      CAN7  Male       9.5 42-43           9  \n 4     52392 United States  2234      US6   Female     9.5 40              7.5\n 5     52393 United Kingdom 2222      UK4   Female     9   39-40           7  \n 6     52394 United States  2173      US15  Male      10.5 43-44          10  \n 7     52395 Germany        2200      GER2  Female     9   39-40           7  \n 8     52396 Canada         2238      CAN5  Male      10   43              9.5\n 9     52397 United States  2191      US13  Male      10.5 43-44          10  \n10     52398 United Kingdom 2237      UK1   Female     9   39-40           7  \n# ℹ 14,957 more rows\n# ℹ 5 more variables: UNITPRICE &lt;dbl&gt;, DISCOUNT &lt;dbl&gt;, YEAR &lt;dbl&gt;, MONTH &lt;dbl&gt;,\n#   SALEPRICE &lt;dbl&gt;\n\n\n\n\n\ndf_pd['DATE']   \n\n0          1/1/2014\n1          1/1/2014\n2          1/1/2014\n3          1/1/2014\n4          1/1/2014\n            ...    \n14962    12/31/2016\n14963    12/31/2016\n14964    12/31/2016\n14965    12/31/2016\n14966    12/31/2016\nName: DATE, Length: 14967, dtype: object\n\n\n\ndf_pd[['DATE', 'UNITPRICE']]   \n\n             DATE  UNITPRICE\n0        1/1/2014        159\n1        1/1/2014        199\n2        1/1/2014        149\n3        1/1/2014        159\n4        1/1/2014        159\n...           ...        ...\n14962  12/31/2016        139\n14963  12/31/2016        149\n14964  12/31/2016        179\n14965  12/31/2016        199\n14966  12/31/2016        139\n\n[14967 rows x 2 columns]\n\n\n\ndf_pd.loc[:,['DATE', 'UNITPRICE']]   \n\n             DATE  UNITPRICE\n0        1/1/2014        159\n1        1/1/2014        199\n2        1/1/2014        149\n3        1/1/2014        159\n4        1/1/2014        159\n...           ...        ...\n14962  12/31/2016        139\n14963  12/31/2016        149\n14964  12/31/2016        179\n14965  12/31/2016        199\n14966  12/31/2016        139\n\n[14967 rows x 2 columns]\n\n\n\ndf_pd.iloc[:,5:8]\n\n       GENDER  SIZE_US SIZE_EUROPE\n0        Male     11.0          44\n1        Male     11.5       44-45\n2        Male      9.5       42-43\n3      Female      9.5          40\n4      Female      9.0       39-40\n...       ...      ...         ...\n14962    Male      9.5       42-43\n14963  Female     12.0       42-43\n14964    Male     10.5       43-44\n14965  Female      9.5          40\n14966  Female      6.5          37\n\n[14967 rows x 3 columns]\n\n\n\ndf_pd.iloc[:,[3,5,8]]\n\n      PRODUCTID  GENDER  SIZE_UK\n0          2152    Male     10.5\n1          2230    Male     11.0\n2          2160    Male      9.0\n3          2234  Female      7.5\n4          2222  Female      7.0\n...         ...     ...      ...\n14962      2154    Male      9.0\n14963      2181  Female     10.0\n14964      2203    Male     10.0\n14965      2231  Female      7.5\n14966      2156  Female      4.5\n\n[14967 rows x 3 columns]\n\n\n\ndf_pd.filter(['YEAR','SALEPRICE', 'DISCOUNT', 'UNITPRICE'])\n\n       YEAR  SALEPRICE  DISCOUNT  UNITPRICE\n0      2014      159.0       0.0        159\n1      2014      159.2       0.2        199\n2      2014      119.2       0.2        149\n3      2014      159.0       0.0        159\n4      2014      159.0       0.0        159\n...     ...        ...       ...        ...\n14962  2016      139.0       0.0        139\n14963  2016      149.0       0.0        149\n14964  2016      125.3       0.3        179\n14965  2016      199.0       0.0        199\n14966  2016      125.1       0.1        139\n\n[14967 rows x 4 columns]\n\n\n\ndf_pd.filter(['YEAR','SALEPRICE', 'DISCOUNT', 'UNITPRICE'])\n\n       YEAR  SALEPRICE  DISCOUNT  UNITPRICE\n0      2014      159.0       0.0        159\n1      2014      159.2       0.2        199\n2      2014      119.2       0.2        149\n3      2014      159.0       0.0        159\n4      2014      159.0       0.0        159\n...     ...        ...       ...        ...\n14962  2016      139.0       0.0        139\n14963  2016      149.0       0.0        149\n14964  2016      125.3       0.3        179\n14965  2016      199.0       0.0        199\n14966  2016      125.1       0.1        139\n\n[14967 rows x 4 columns]\n\n\n\n #RegularExpression(Regex)\ndf_pd.filter(regex =\"PRICE$\") #Ends with Price\n\n       UNITPRICE  SALEPRICE\n0            159      159.0\n1            199      159.2\n2            149      119.2\n3            159      159.0\n4            159      159.0\n...          ...        ...\n14962        139      139.0\n14963        149      149.0\n14964        179      125.3\n14965        199      199.0\n14966        139      125.1\n\n[14967 rows x 2 columns]\n\n\n\ndf_pd.filter(regex =\"ˆSIZE\") #Starts with SIZE\n\nEmpty DataFrame\nColumns: []\nIndex: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, ...]\n\n[14967 rows x 0 columns]\n\n\n\ndf_pd.filter(regex =\"PRICE\") #Contains the word Price\n\n       UNITPRICE  SALEPRICE\n0            159      159.0\n1            199      159.2\n2            149      119.2\n3            159      159.0\n4            159      159.0\n...          ...        ...\n14962        139      139.0\n14963        149      149.0\n14964        179      125.3\n14965        199      199.0\n14966        139      125.1\n\n[14967 rows x 2 columns]\n\n\n\ndf_pd.select_dtypes('object')\n\n      INVOICENO        DATE         COUNTRY  ...  GENDER SIZE_EUROPE MONTH\n0         52389    1/1/2014  United Kingdom  ...    Male          44     1\n1         52390    1/1/2014   United States  ...    Male       44-45     1\n2         52391    1/1/2014          Canada  ...    Male       42-43     1\n3         52392    1/1/2014   United States  ...  Female          40     1\n4         52393    1/1/2014  United Kingdom  ...  Female       39-40     1\n...         ...         ...             ...  ...     ...         ...   ...\n14962     65773  12/31/2016  United Kingdom  ...    Male       42-43    12\n14963     65774  12/31/2016   United States  ...  Female       42-43    12\n14964     65775  12/31/2016          Canada  ...    Male       43-44    12\n14965     65776  12/31/2016         Germany  ...  Female          40    12\n14966     65777  12/31/2016         Germany  ...  Female          37    12\n\n[14967 rows x 8 columns]\n\n\n\ndf_pd.select_dtypes('int')\n\n       UNITPRICE  YEAR\n0            159  2014\n1            199  2014\n2            149  2014\n3            159  2014\n4            159  2014\n...          ...   ...\n14962        139  2016\n14963        149  2016\n14964        179  2016\n14965        199  2016\n14966        139  2016\n\n[14967 rows x 2 columns]\n\n\n\ndf_pd.loc[:,df_pd.columns.str.startswith('SIZE')]\n\n       SIZE_US SIZE_EUROPE  SIZE_UK\n0         11.0          44     10.5\n1         11.5       44-45     11.0\n2          9.5       42-43      9.0\n3          9.5          40      7.5\n4          9.0       39-40      7.0\n...        ...         ...      ...\n14962      9.5       42-43      9.0\n14963     12.0       42-43     10.0\n14964     10.5       43-44     10.0\n14965      9.5          40      7.5\n14966      6.5          37      4.5\n\n[14967 rows x 3 columns]\n\n\n\ndf_pd.loc[:,df_pd.columns.str.contains('PRICE')]\n\n       UNITPRICE  SALEPRICE\n0            159      159.0\n1            199      159.2\n2            149      119.2\n3            159      159.0\n4            159      159.0\n...          ...        ...\n14962        139      139.0\n14963        149      149.0\n14964        179      125.3\n14965        199      199.0\n14966        139      125.1\n\n[14967 rows x 2 columns]\n\n\n\ndf_pd.loc[:,df_pd.columns.str.endswith('PRICE')]\n\n       UNITPRICE  SALEPRICE\n0            159      159.0\n1            199      159.2\n2            149      119.2\n3            159      159.0\n4            159      159.0\n...          ...        ...\n14962        139      139.0\n14963        149      149.0\n14964        179      125.3\n14965        199      199.0\n14966        139      125.1\n\n[14967 rows x 2 columns]\n\n\n\n# Dropping columns \ndf_pd.drop(columns =['SIZE_EUROPE', 'SIZE_UK'], axis=1)\n\n      INVOICENO        DATE         COUNTRY  ...  YEAR MONTH SALEPRICE\n0         52389    1/1/2014  United Kingdom  ...  2014     1     159.0\n1         52390    1/1/2014   United States  ...  2014     1     159.2\n2         52391    1/1/2014          Canada  ...  2014     1     119.2\n3         52392    1/1/2014   United States  ...  2014     1     159.0\n4         52393    1/1/2014  United Kingdom  ...  2014     1     159.0\n...         ...         ...             ...  ...   ...   ...       ...\n14962     65773  12/31/2016  United Kingdom  ...  2016    12     139.0\n14963     65774  12/31/2016   United States  ...  2016    12     149.0\n14964     65775  12/31/2016          Canada  ...  2016    12     125.3\n14965     65776  12/31/2016         Germany  ...  2016    12     199.0\n14966     65777  12/31/2016         Germany  ...  2016    12     125.1\n\n[14967 rows x 12 columns]\n\n\n\n# Dropping columns \ndf_pd.drop(columns =['SIZE_EUROPE', 'SIZE_UK'], axis=1)\\\n    .pipe(lambda x: x.info())\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 14967 entries, 0 to 14966\nData columns (total 12 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   INVOICENO  14967 non-null  object \n 1   DATE       14967 non-null  object \n 2   COUNTRY    14967 non-null  object \n 3   PRODUCTID  14967 non-null  object \n 4   SHOP       14967 non-null  object \n 5   GENDER     14967 non-null  object \n 6   SIZE_US    14967 non-null  float64\n 7   UNITPRICE  14967 non-null  int64  \n 8   DISCOUNT   14967 non-null  float64\n 9   YEAR       14967 non-null  int64  \n 10  MONTH      14967 non-null  object \n 11  SALEPRICE  14967 non-null  float64\ndtypes: float64(3), int64(2), object(7)\nmemory usage: 1.4+ MB\n\n\n\n# Rearranging columns \n# Sorting Alphabetically\ndf_pd.reindex(sorted(df_pd.columns), axis =1)\n\n              COUNTRY        DATE  DISCOUNT  ... SIZE_US UNITPRICE  YEAR\n0      United Kingdom    1/1/2014       0.0  ...    11.0       159  2014\n1       United States    1/1/2014       0.2  ...    11.5       199  2014\n2              Canada    1/1/2014       0.2  ...     9.5       149  2014\n3       United States    1/1/2014       0.0  ...     9.5       159  2014\n4      United Kingdom    1/1/2014       0.0  ...     9.0       159  2014\n...               ...         ...       ...  ...     ...       ...   ...\n14962  United Kingdom  12/31/2016       0.0  ...     9.5       139  2016\n14963   United States  12/31/2016       0.0  ...    12.0       149  2016\n14964          Canada  12/31/2016       0.3  ...    10.5       179  2016\n14965         Germany  12/31/2016       0.0  ...     9.5       199  2016\n14966         Germany  12/31/2016       0.1  ...     6.5       139  2016\n\n[14967 rows x 14 columns]\n\n\n\n# Rearranging columns \n# Sorting As You Want (ASY)\ncol_first = ['YEAR','MONTH']\ncol_rest = df_pd.columns.difference(col_first, sort=False).to_list()\ndf_pd2 = df_pd [col_first +col_rest]\ndf_pd2.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 14967 entries, 0 to 14966\nData columns (total 14 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   YEAR         14967 non-null  int64  \n 1   MONTH        14967 non-null  object \n 2   INVOICENO    14967 non-null  object \n 3   DATE         14967 non-null  object \n 4   COUNTRY      14967 non-null  object \n 5   PRODUCTID    14967 non-null  object \n 6   SHOP         14967 non-null  object \n 7   GENDER       14967 non-null  object \n 8   SIZE_US      14967 non-null  float64\n 9   SIZE_EUROPE  14967 non-null  object \n 10  SIZE_UK      14967 non-null  float64\n 11  UNITPRICE    14967 non-null  int64  \n 12  DISCOUNT     14967 non-null  float64\n 13  SALEPRICE    14967 non-null  float64\ndtypes: float64(4), int64(2), object(8)\nmemory usage: 1.6+ MB\n\n\n\n\n\n\n\n3.9.4 4th Verb - rename () Function\n\ndplyrpandas\n\n\n\ndf |&gt;\n    rename(INVOICE = INVOICENO,\n    PRODUCT = PRODUCTID) |&gt;\n    glimpse()\n\nRows: 14,967\nColumns: 14\n$ INVOICE     &lt;dbl&gt; 52389, 52390, 52391, 52392, 52393, 52394, 52395, 52396, 52…\n$ DATE        &lt;date&gt; 2014-01-01, 2014-01-01, 2014-01-01, 2014-01-01, 2014-01-0…\n$ COUNTRY     &lt;chr&gt; \"United Kingdom\", \"United States\", \"Canada\", \"United State…\n$ PRODUCT     &lt;chr&gt; \"2152\", \"2230\", \"2160\", \"2234\", \"2222\", \"2173\", \"2200\", \"2…\n$ SHOP        &lt;chr&gt; \"UK2\", \"US15\", \"CAN7\", \"US6\", \"UK4\", \"US15\", \"GER2\", \"CAN5…\n$ GENDER      &lt;chr&gt; \"Male\", \"Male\", \"Male\", \"Female\", \"Female\", \"Male\", \"Femal…\n$ SIZE_US     &lt;dbl&gt; 11.0, 11.5, 9.5, 9.5, 9.0, 10.5, 9.0, 10.0, 10.5, 9.0, 10.…\n$ SIZE_EUROPE &lt;chr&gt; \"44\", \"44-45\", \"42-43\", \"40\", \"39-40\", \"43-44\", \"39-40\", \"…\n$ SIZE_UK     &lt;dbl&gt; 10.5, 11.0, 9.0, 7.5, 7.0, 10.0, 7.0, 9.5, 10.0, 7.0, 9.5,…\n$ UNITPRICE   &lt;dbl&gt; 159, 199, 149, 159, 159, 159, 179, 169, 139, 149, 129, 169…\n$ DISCOUNT    &lt;dbl&gt; 0.0, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1…\n$ YEAR        &lt;dbl&gt; 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014…\n$ MONTH       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ SALEPRICE   &lt;dbl&gt; 159.0, 159.2, 119.2, 159.0, 159.0, 159.0, 179.0, 169.0, 13…\n\n\n\n\n\n(df_pd.rename(columns = {\"PRODUCTID\": \"PRODUCT\", \"INVOICENO\": \"INVOICE\"})\n     .pipe(lambda x: x.info())\n)\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 14967 entries, 0 to 14966\nData columns (total 14 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   INVOICE      14967 non-null  object \n 1   DATE         14967 non-null  object \n 2   COUNTRY      14967 non-null  object \n 3   PRODUCT      14967 non-null  object \n 4   SHOP         14967 non-null  object \n 5   GENDER       14967 non-null  object \n 6   SIZE_US      14967 non-null  float64\n 7   SIZE_EUROPE  14967 non-null  object \n 8   SIZE_UK      14967 non-null  float64\n 9   UNITPRICE    14967 non-null  int64  \n 10  DISCOUNT     14967 non-null  float64\n 11  YEAR         14967 non-null  int64  \n 12  MONTH        14967 non-null  object \n 13  SALEPRICE    14967 non-null  float64\ndtypes: float64(4), int64(2), object(8)\nmemory usage: 1.6+ MB\n\n\n\n\n\n\n\n3.9.5 5th Verb - mutate () Function\n\ndplyrpandas\n\n\n\ndf |&gt;\n    mutate(NECOLUMN = 5,\n    SALESPRICE2 = UNITPRICE*(1-DISCOUNT)) |&gt;\n    glimpse()\n\nRows: 14,967\nColumns: 16\n$ INVOICENO   &lt;dbl&gt; 52389, 52390, 52391, 52392, 52393, 52394, 52395, 52396, 52…\n$ DATE        &lt;date&gt; 2014-01-01, 2014-01-01, 2014-01-01, 2014-01-01, 2014-01-0…\n$ COUNTRY     &lt;chr&gt; \"United Kingdom\", \"United States\", \"Canada\", \"United State…\n$ PRODUCTID   &lt;chr&gt; \"2152\", \"2230\", \"2160\", \"2234\", \"2222\", \"2173\", \"2200\", \"2…\n$ SHOP        &lt;chr&gt; \"UK2\", \"US15\", \"CAN7\", \"US6\", \"UK4\", \"US15\", \"GER2\", \"CAN5…\n$ GENDER      &lt;chr&gt; \"Male\", \"Male\", \"Male\", \"Female\", \"Female\", \"Male\", \"Femal…\n$ SIZE_US     &lt;dbl&gt; 11.0, 11.5, 9.5, 9.5, 9.0, 10.5, 9.0, 10.0, 10.5, 9.0, 10.…\n$ SIZE_EUROPE &lt;chr&gt; \"44\", \"44-45\", \"42-43\", \"40\", \"39-40\", \"43-44\", \"39-40\", \"…\n$ SIZE_UK     &lt;dbl&gt; 10.5, 11.0, 9.0, 7.5, 7.0, 10.0, 7.0, 9.5, 10.0, 7.0, 9.5,…\n$ UNITPRICE   &lt;dbl&gt; 159, 199, 149, 159, 159, 159, 179, 169, 139, 149, 129, 169…\n$ DISCOUNT    &lt;dbl&gt; 0.0, 0.2, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1…\n$ YEAR        &lt;dbl&gt; 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014, 2014…\n$ MONTH       &lt;dbl&gt; 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1…\n$ SALEPRICE   &lt;dbl&gt; 159.0, 159.2, 119.2, 159.0, 159.0, 159.0, 179.0, 169.0, 13…\n$ NECOLUMN    &lt;dbl&gt; 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5…\n$ SALESPRICE2 &lt;dbl&gt; 159.0, 159.2, 119.2, 159.0, 159.0, 159.0, 179.0, 169.0, 13…\n\n\n\n\n\ndf_pd['NEWCOLUMN'] = 5\ndf_pd.info()     \n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 14967 entries, 0 to 14966\nData columns (total 15 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   INVOICENO    14967 non-null  object \n 1   DATE         14967 non-null  object \n 2   COUNTRY      14967 non-null  object \n 3   PRODUCTID    14967 non-null  object \n 4   SHOP         14967 non-null  object \n 5   GENDER       14967 non-null  object \n 6   SIZE_US      14967 non-null  float64\n 7   SIZE_EUROPE  14967 non-null  object \n 8   SIZE_UK      14967 non-null  float64\n 9   UNITPRICE    14967 non-null  int64  \n 10  DISCOUNT     14967 non-null  float64\n 11  YEAR         14967 non-null  int64  \n 12  MONTH        14967 non-null  object \n 13  SALEPRICE    14967 non-null  float64\n 14  NEWCOLUMN    14967 non-null  int64  \ndtypes: float64(4), int64(3), object(8)\nmemory usage: 1.7+ MB\n\n\n\ndf_pd.drop(columns = ['NEWCOLUMN'], axis = 1, inplace = True)   \ndf_pd.info() \n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 14967 entries, 0 to 14966\nData columns (total 14 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   INVOICENO    14967 non-null  object \n 1   DATE         14967 non-null  object \n 2   COUNTRY      14967 non-null  object \n 3   PRODUCTID    14967 non-null  object \n 4   SHOP         14967 non-null  object \n 5   GENDER       14967 non-null  object \n 6   SIZE_US      14967 non-null  float64\n 7   SIZE_EUROPE  14967 non-null  object \n 8   SIZE_UK      14967 non-null  float64\n 9   UNITPRICE    14967 non-null  int64  \n 10  DISCOUNT     14967 non-null  float64\n 11  YEAR         14967 non-null  int64  \n 12  MONTH        14967 non-null  object \n 13  SALEPRICE    14967 non-null  float64\ndtypes: float64(4), int64(2), object(8)\nmemory usage: 1.6+ MB\n\n\n\ndf_pd['SALEPRICE2']=df_pd['UNITPRICE']*(1-df_pd['DISCOUNT'])\ndf_pd.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 14967 entries, 0 to 14966\nData columns (total 15 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   INVOICENO    14967 non-null  object \n 1   DATE         14967 non-null  object \n 2   COUNTRY      14967 non-null  object \n 3   PRODUCTID    14967 non-null  object \n 4   SHOP         14967 non-null  object \n 5   GENDER       14967 non-null  object \n 6   SIZE_US      14967 non-null  float64\n 7   SIZE_EUROPE  14967 non-null  object \n 8   SIZE_UK      14967 non-null  float64\n 9   UNITPRICE    14967 non-null  int64  \n 10  DISCOUNT     14967 non-null  float64\n 11  YEAR         14967 non-null  int64  \n 12  MONTH        14967 non-null  object \n 13  SALEPRICE    14967 non-null  float64\n 14  SALEPRICE2   14967 non-null  float64\ndtypes: float64(5), int64(2), object(8)\nmemory usage: 1.7+ MB\n\n\n\n# Using the assign() function\n(df_pd[['PRODUCTID', 'UNITPRICE', 'DISCOUNT']]\\\n    .assign(SALEPRICE3 =lambda x: x.UNITPRICE*(1-x.DISCOUNT)) \\\n    .head(5)\n)\n\n  PRODUCTID  UNITPRICE  DISCOUNT  SALEPRICE3\n0      2152        159       0.0       159.0\n1      2230        199       0.2       159.2\n2      2160        149       0.2       119.2\n3      2234        159       0.0       159.0\n4      2222        159       0.0       159.0\n\n\n\n\n\n\n\n3.9.6 6th Verbs - group_by () and summarize () Functions\n     Figure 3.1 presents Split Apply Combine principle in group_by () and summarize () functions.\n\n\n\n\n\n\nFigure 3.1: Split Apply Combine Principle\n\n\n\n\ndplyrpandas\n\n\n\ndf |&gt;\n    group_by(COUNTRY) |&gt;\n    summarize (AVGPRICE = mean(UNITPRICE, na.rm = TRUE))\n\n# A tibble: 4 × 2\n  COUNTRY        AVGPRICE\n  &lt;chr&gt;             &lt;dbl&gt;\n1 Canada             165.\n2 Germany            164.\n3 United Kingdom     166.\n4 United States      163.\n\n\n\ndf |&gt;\n    group_by(COUNTRY) |&gt;\n    summarize (AVGPRICE = mean(UNITPRICE, na.rm = TRUE),\n    AVGSALEPRICE = mean (SALEPRICE, na.rm = TRUE))\n\n# A tibble: 4 × 3\n  COUNTRY        AVGPRICE AVGSALEPRICE\n  &lt;chr&gt;             &lt;dbl&gt;        &lt;dbl&gt;\n1 Canada             165.         144.\n2 Germany            164.         144.\n3 United Kingdom     166.         146.\n4 United States      163.         144.\n\n\n\n# Summary Statistics \ndf %&gt;%\n  select(UNITPRICE, SALEPRICE) %&gt;%\n  summarize(across(where(is.numeric), \n                   .fns = list(N = ~length(.),\n                               Mean = mean, \n                               Std = sd,\n                               Median = median, \n                               P25 = ~quantile(.,0.25), \n                               P75 = ~quantile(., 0.75)\n                               )\n                   )) %&gt;%\n  pivot_longer(everything(), names_sep='_', names_to=c('variable', '.value'))  \n\n# A tibble: 2 × 7\n  variable      N  Mean   Std Median   P25   P75\n  &lt;chr&gt;     &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1 UNITPRICE 14967  164.  22.9    159  149    179\n2 SALEPRICE 14967  144.  35.2    149  125.   169\n\n\n\n\n\ndf_pd.groupby(['COUNTRY'])['UNITPRICE'].mean()\n\nCOUNTRY\nCanada            164.691057\nGermany           164.163934\nUnited Kingdom    165.614853\nUnited States     163.490316\nName: UNITPRICE, dtype: float64\n\n\n\ndf_pd.groupby(['COUNTRY'])[['UNITPRICE', 'SALEPRICE']].mean()\n\n                 UNITPRICE   SALEPRICE\nCOUNTRY                               \nCanada          164.691057  144.228963\nGermany         164.163934  143.574658\nUnited Kingdom  165.614853  145.505872\nUnited States   163.490316  143.727421\n\n\n\ndf_pd.groupby(['COUNTRY']) [['UNITPRICE', 'SALEPRICE']] \\\n    .agg(np.mean) \n\n                 UNITPRICE   SALEPRICE\nCOUNTRY                               \nCanada          164.691057  144.228963\nGermany         164.163934  143.574658\nUnited Kingdom  165.614853  145.505872\nUnited States   163.490316  143.727421\n\n\n\ndf_pd.groupby(['COUNTRY']) [['UNITPRICE', 'SALEPRICE']] \\\n    .agg(\"mean\") \n\n                 UNITPRICE   SALEPRICE\nCOUNTRY                               \nCanada          164.691057  144.228963\nGermany         164.163934  143.574658\nUnited Kingdom  165.614853  145.505872\nUnited States   163.490316  143.727421\n\n\n\ndf_pd.groupby(['COUNTRY']) [['UNITPRICE', 'SALEPRICE']] \\\n    .agg(AVG_UNITPRICE =(\"UNITPRICE\",\"mean\"),\n    AVG_LISTPRICE =(\"SALEPRICE\",\"mean\"))\n\n                AVG_UNITPRICE  AVG_LISTPRICE\nCOUNTRY                                     \nCanada             164.691057     144.228963\nGermany            164.163934     143.574658\nUnited Kingdom     165.614853     145.505872\nUnited States      163.490316     143.727421\n\n\n\ndf_pd.groupby(['COUNTRY']) [['UNITPRICE', 'SALEPRICE']] \\\n    .agg(AVG_UNITPRICE =(\"UNITPRICE\",\"mean\"),\n    AVG_LISTPRICE =(\"SALEPRICE\",\"mean\"),\n    TOTALN=(\"SALEPRICE\",\"size\"), # size function for n\n    TOTALOBS=(\"SALEPRICE\",\"count\") # count function for n\n )\n\n                AVG_UNITPRICE  AVG_LISTPRICE  TOTALN  TOTALOBS\nCOUNTRY                                                       \nCanada             164.691057     144.228963    2952      2952\nGermany            164.163934     143.574658    4392      4392\nUnited Kingdom     165.614853     145.505872    1737      1737\nUnited States      163.490316     143.727421    5886      5886\n\n\n\n# Defining a Function\ndef percentile(n):\n    def percentile_(x):\n        return x.quantile(n)\n    percentile_.__name__ ='percentile_{:02.0f}'.format(n*100)\n    return percentile_\n\n# Some summary statistics \ndf_pd[['UNITPRICE', 'SALEPRICE']] \\\n    .agg(['count', 'mean', 'std', 'median', percentile(0.25), percentile (0.75)]) \\\n    .transpose() \\\n    .reset_index() \\\n    .rename(columns = {\"index\": \"variables\", \"percentile_25\": \"P25\", \"percentile_75\": \"P75\", 'count': \"N\"}) \\\n    .round(3) \n\n   variables        N     mean     std  median    P25    P75\n0  UNITPRICE  14967.0  164.171  22.941   159.0  149.0  179.0\n1  SALEPRICE  14967.0  143.988  35.181   149.0  125.1  169.0\n\n\n\n# Summary Statistics \nagg_dict = {\n    \"N\": \"count\",\n    'Mean':\"mean\",\n    \"Std. Dev\" : \"std\",\n    'P25': lambda x: x.quantile(0.25),\n    'Median': 'median',\n    'p75': lambda x: x.quantile(0.75)\n}\n\ndf_pd[['UNITPRICE', 'SALEPRICE']].agg(agg_dict)",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Exploratory Data Analysis (EDA)</span>"
    ]
  },
  {
    "objectID": "eda.html#reshaping-data",
    "href": "eda.html#reshaping-data",
    "title": "3  Exploratory Data Analysis (EDA)",
    "section": "3.10 Reshaping Data",
    "text": "3.10 Reshaping Data\n\n     Before we discuss about reshaping of the data, we need to discuss about tidy format of the data. Data can come in many shapes, but not all shapes are useful for data analysis. In most cases, tidy format of the data is most useful for analysis. Therefore, if the data is untidy, we need to make it tidy first. There are three interrelated rules which make a dataset tidy (Wickham, Çetinkaya-Rundel, and Grolemund 2023). These rules are given below. Figure 3.2 visually represents tidy principle.\n\nEach variable must have its own column\nEach observation must have its own row\nEach value must have its own cell\n\n\n\n\n\n\n\nFigure 3.2: Tidy Principle\n\n\n\n     For analysis, many times we need to change the format of our dataset and we call it reshaping. Data come primarily in two shapes -wide and long. Sometimes wide format is called “record” format and long format is called “stacked” format. In wide format data, there is one row for each subject (units of observation). Data is long when there are multiple rows for each subject (units of observations).\n     This reshaping can be two types - a) long to wide and 2) wide to long. Long-to-wide means reshaping a long data, which has many rows, into wide format, which has many variables. In wide-to-long format, we do otherwise. For analytical purpose, reshaping data is useful; so, we need to know how to do the reshaping.\n     Whether a given dataset (e.g., Table 3.2) is in wide or long format depends on our research questions (on what variables we are interested in and how we conceive of our data). If we are interested in variable Temp and Month variable is the unit of obsevation, then the dataset in Table 3.2 is in long format because Month is repeated in mutiple rows.\n\n\nairquality = airquality\n\nexamp = airquality |&gt;\n    slice(1:10)\n\n\n\n\n\nTable 3.2: Which Format - Long or Wide\n\n\n\n\n\n\n\nOzone\nSolar.R\nWind\nTemp\nMonth\nDay\n\n\n\n\n41\n190\n7.4\n67\n5\n1\n\n\n36\n118\n8.0\n72\n5\n2\n\n\n12\n149\n12.6\n74\n5\n3\n\n\n18\n313\n11.5\n62\n5\n4\n\n\nNA\nNA\n14.3\n56\n5\n5\n\n\n28\nNA\n14.9\n66\n5\n6\n\n\n23\n299\n8.6\n65\n5\n7\n\n\n19\n99\n13.8\n59\n5\n8\n\n\n8\n19\n20.1\n61\n5\n9\n\n\nNA\n194\n8.6\n69\n5\n10\n\n\n\n\n\n\n\n\n\n\n\n\n3.10.1 Long-to-Wide Format\n\n     To make a long dataset to wide, we can use pivot_wider() function from tidyr package in R and pivot() function from pandas in python.\n\n\ntidyrpandas\n\n\n\ntidyr::us_rent_income\n\n# A tibble: 104 × 5\n   GEOID NAME       variable estimate   moe\n   &lt;chr&gt; &lt;chr&gt;      &lt;chr&gt;       &lt;dbl&gt; &lt;dbl&gt;\n 1 01    Alabama    income      24476   136\n 2 01    Alabama    rent          747     3\n 3 02    Alaska     income      32940   508\n 4 02    Alaska     rent         1200    13\n 5 04    Arizona    income      27517   148\n 6 04    Arizona    rent          972     4\n 7 05    Arkansas   income      23789   165\n 8 05    Arkansas   rent          709     5\n 9 06    California income      29454   109\n10 06    California rent         1358     3\n# ℹ 94 more rows\n\n\n\ntidyr::us_rent_income |&gt;\n    pivot_wider(\n        names_from = variable, \n        values_from = c(estimate, moe)\n    )\n\n# A tibble: 52 × 6\n   GEOID NAME                 estimate_income estimate_rent moe_income moe_rent\n   &lt;chr&gt; &lt;chr&gt;                          &lt;dbl&gt;         &lt;dbl&gt;      &lt;dbl&gt;    &lt;dbl&gt;\n 1 01    Alabama                        24476           747        136        3\n 2 02    Alaska                         32940          1200        508       13\n 3 04    Arizona                        27517           972        148        4\n 4 05    Arkansas                       23789           709        165        5\n 5 06    California                     29454          1358        109        3\n 6 08    Colorado                       32401          1125        109        5\n 7 09    Connecticut                    35326          1123        195        5\n 8 10    Delaware                       31560          1076        247       10\n 9 11    District of Columbia           43198          1424        681       17\n10 12    Florida                        25952          1077         70        3\n# ℹ 42 more rows\n\n\n\n\n\n# install palmerpenguins package\n# pip install palmerpenguins\nimport palmerpenguins\npenguins = palmerpenguins.load_penguins()\n\n\npenguins[[\"island\", \"bill_length_mm\"]] \\\n    .pivot(columns = \"island\", values = \"bill_length_mm\") \\\n    .fillna(0)\n\nisland  Biscoe  Dream  Torgersen\n0          0.0    0.0       39.1\n1          0.0    0.0       39.5\n2          0.0    0.0       40.3\n3          0.0    0.0        0.0\n4          0.0    0.0       36.7\n..         ...    ...        ...\n339        0.0   55.8        0.0\n340        0.0   43.5        0.0\n341        0.0   49.6        0.0\n342        0.0   50.8        0.0\n343        0.0   50.2        0.0\n\n[344 rows x 3 columns]\n\n\n\n\n\n\n\n3.10.2 Wide-to-Long Format\n\n     To make a wide dataset to long, we can use pivot_longer() function from tidyr package in R and melt() function from pandas in python.\n\n\ntidyrpandas\n\n\n\nrelig_income\n\n# A tibble: 18 × 11\n   religion `&lt;$10k` `$10-20k` `$20-30k` `$30-40k` `$40-50k` `$50-75k` `$75-100k`\n   &lt;chr&gt;      &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;      &lt;dbl&gt;\n 1 Agnostic      27        34        60        81        76       137        122\n 2 Atheist       12        27        37        52        35        70         73\n 3 Buddhist      27        21        30        34        33        58         62\n 4 Catholic     418       617       732       670       638      1116        949\n 5 Don’t k…      15        14        15        11        10        35         21\n 6 Evangel…     575       869      1064       982       881      1486        949\n 7 Hindu          1         9         7         9        11        34         47\n 8 Histori…     228       244       236       238       197       223        131\n 9 Jehovah…      20        27        24        24        21        30         15\n10 Jewish        19        19        25        25        30        95         69\n11 Mainlin…     289       495       619       655       651      1107        939\n12 Mormon        29        40        48        51        56       112         85\n13 Muslim         6         7         9        10         9        23         16\n14 Orthodox      13        17        23        32        32        47         38\n15 Other C…       9         7        11        13        13        14         18\n16 Other F…      20        33        40        46        49        63         46\n17 Other W…       5         2         3         4         2         7          3\n18 Unaffil…     217       299       374       365       341       528        407\n# ℹ 3 more variables: `$100-150k` &lt;dbl&gt;, `&gt;150k` &lt;dbl&gt;,\n#   `Don't know/refused` &lt;dbl&gt;\n\n\n\nrelig_income |&gt;\n    pivot_longer(\n        cols = !c(religion),\n        names_to = \"income\",\n        values_to = \"count\"\n    )\n\n# A tibble: 180 × 3\n   religion income             count\n   &lt;chr&gt;    &lt;chr&gt;              &lt;dbl&gt;\n 1 Agnostic &lt;$10k                 27\n 2 Agnostic $10-20k               34\n 3 Agnostic $20-30k               60\n 4 Agnostic $30-40k               81\n 5 Agnostic $40-50k               76\n 6 Agnostic $50-75k              137\n 7 Agnostic $75-100k             122\n 8 Agnostic $100-150k            109\n 9 Agnostic &gt;150k                 84\n10 Agnostic Don't know/refused    96\n# ℹ 170 more rows\n\n\n\n\n\npenguins.melt(value_vars=[\"bill_length_mm\", \"bill_depth_mm\",\"flipper_length_mm\", \"body_mass_g\"],\n              id_vars = ['species', 'island', 'sex', 'year']\n              )\n\n        species     island     sex  year        variable   value\n0        Adelie  Torgersen    male  2007  bill_length_mm    39.1\n1        Adelie  Torgersen  female  2007  bill_length_mm    39.5\n2        Adelie  Torgersen  female  2007  bill_length_mm    40.3\n3        Adelie  Torgersen     NaN  2007  bill_length_mm     NaN\n4        Adelie  Torgersen  female  2007  bill_length_mm    36.7\n...         ...        ...     ...   ...             ...     ...\n1371  Chinstrap      Dream    male  2009     body_mass_g  4000.0\n1372  Chinstrap      Dream  female  2009     body_mass_g  3400.0\n1373  Chinstrap      Dream    male  2009     body_mass_g  3775.0\n1374  Chinstrap      Dream    male  2009     body_mass_g  4100.0\n1375  Chinstrap      Dream  female  2009     body_mass_g  3775.0\n\n[1376 rows x 6 columns]",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Exploratory Data Analysis (EDA)</span>"
    ]
  },
  {
    "objectID": "eda.html#merging-datasets",
    "href": "eda.html#merging-datasets",
    "title": "3  Exploratory Data Analysis (EDA)",
    "section": "3.11 Merging Datasets",
    "text": "3.11 Merging Datasets\n\n     Many times, for analysis purposes, we need to join two datasets. This process is also called merging3. There are different types of joining. So, it is important to learn about those joining techniques. In Figure 3.3 shows the joining technique and functions using dplyr in R. Below all of these joining functions are explained.\n\nleft_join(): The merged dataset contains all observations fromthe first (or left) dataset and only matched observations from the second (or right) dataset\nright_join(): The merged dataset contains only matched observations from the first (or left) dataset and all observations from the second (or right) dataset\ninner_join(): The merged dataset contains only matched observations from both datasets\nsemi_join(): The merged dataset contains matched observations from the first (or left) dataset. Please note that semi_join() differs from inner_join() in that inner_join() will return one row of first dataset (x) for each matching row of second dataset (y), whereas semi_join() will never duplicate rows of x.\nfull_join(): The merged dataset contains all observations from both datasets\nanti_join(): The merged dataset contains only not matched observations from the first (or left) dataset and contains only the variable from the left dataset\n\n\n\n\n\n\n\nFigure 3.3: Joining Datasets\n\n\n\n     Table 3.3 compares the dplyr joining functions with equivalent joining functions from pandas.\n\n\n\n\nTable 3.3: Joining Functions - dplyr vs pandas\n\n\n\n\n\n\n\ndplyr\npandas\nDescription\n\n\n\n\nleft_join()\npd.merge(df1, df2, on='key', how='left')\nJoin matching rows from df2 to df1, keeping all rows from df1.\n\n\nright_join()\npd.merge(df1, df2, on='key', how='right')\nJoin matching rows from df1 to df2, keeping all rows from df2.\n\n\ninner_join()\npd.merge(df1, df2, on='key', how='inner')\nJoin matching rows from both dataframes (default behavior of merge()).\n\n\nfull_join()\npd.merge(df1, df2, on='key', how='outer')\nJoin all rows from both dataframes, filling missing values with NaN.\n\n\nsemi_join()\nNo direct equivalent, but can be achieved using filtering\nKeep rows in df1 where a match exists in df2.\n\n\nanti_join()\nNo direct equivalent, but can be achieved using filtering\nKeep rows in df1 where no match exists in df2.\n\n\n\n\n\n\n\n\n\n\n\n\n\ndplyrpandas\n\n\n\ndata1 = read_csv(\"https://raw.githubusercontent.com/msharifbd/DATA/refs/heads/main/DATA.csv\")\nglimpse(data1)\n\nRows: 6,910\nColumns: 14\n$ companyname     &lt;chr&gt; \"AMERICAN AIRLINES GROUP INC\", \"AMERICAN AIRLINES GROU…\n$ stateincorp     &lt;chr&gt; \"DE\", \"DE\", \"DE\", \"DE\", \"DE\", \"DE\", \"DE\", \"DE\", \"DE\", …\n$ ticker          &lt;chr&gt; \"AAL\", \"AAL\", \"AAL\", \"AAL\", \"AAL\", \"AAL\", \"AAL\", \"AAL\"…\n$ year            &lt;dbl&gt; 2008, 2009, 2010, 2011, 2012, 2013, 2014, 2015, 2016, …\n$ sic             &lt;dbl&gt; 4512, 4512, 4512, 4512, 4512, 4512, 4512, 4512, 4512, …\n$ totalassets     &lt;dbl&gt; 25175.000, 25438.000, 25088.000, 23848.000, 23510.000,…\n$ costofgoodssold &lt;dbl&gt; 20232.000, 16935.000, 18138.000, 20420.000, 20529.000,…\n$ netincome       &lt;dbl&gt; -2071.000, -1468.000, -471.000, -1979.000, -1876.000, …\n$ sale            &lt;dbl&gt; 23766.000, 19917.000, 22170.000, 24022.000, 24855.000,…\n$ advertising     &lt;dbl&gt; 153.000, 153.000, 165.000, 186.000, 153.000, 166.000, …\n$ sellingadmin    &lt;dbl&gt; 3024.000, 2720.000, 2729.000, 2907.000, 2892.000, 4672…\n$ mktvalue        &lt;dbl&gt; 2976.3858, 2571.1835, 2597.5755, 117.3438, 266.5571, 6…\n$ commonequity    &lt;dbl&gt; -2935.000, -3489.000, -3945.000, -7111.000, -7987.000,…\n$ totalliability  &lt;dbl&gt; 28110.000, 28927.000, 29033.000, 30959.000, 31497.000,…\n\n\n\ndata2 = read_csv(\"https://github.com/msharifbd/DATA/raw/refs/heads/main/DATA2.csv\")\nglimpse(data2)\n\nRows: 43,147\nColumns: 13\n$ ticker                    &lt;chr&gt; \"MLP\", \"MLP\", \"MLP\", \"RCPIQ\", \"RCPIQ\", \"RCPI…\n$ cik_code                  &lt;dbl&gt; 63330, 63330, 63330, 776008, 776008, 776008,…\n$ auditor                   &lt;chr&gt; \"Accuity LLP\", \"Accuity LLP\", \"Accuity LLP\",…\n$ INTERNALCONTROL_EFFECTIVE &lt;chr&gt; \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"Yes\", \"N…\n$ year_ended_date           &lt;date&gt; 2017-12-31, 2018-12-31, 2019-12-31, 2004-12…\n$ financials_date           &lt;date&gt; 2017-12-31, 2018-12-31, 2019-12-31, 2004-12…\n$ fiscal_year               &lt;dbl&gt; 2017, 2018, 2019, 2004, 2005, 2006, 2007, 20…\n$ signature_date            &lt;date&gt; 2018-02-23, 2019-03-01, 2020-02-28, 2005-04…\n$ NUMBEROFCONTROLWEAKNESS   &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 1, 4, 0, 0, 0, 0, 0, 0, 0,…\n$ audit_fees                &lt;dbl&gt; 206000, 209000, 213000, 224209, 382454, 4155…\n$ non_audit_fees            &lt;dbl&gt; 29000, 30000, 30000, 188081, 92869, 61351, 3…\n$ year                      &lt;dbl&gt; 2017, 2018, 2019, 2004, 2005, 2006, 2007, 20…\n$ big4                      &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,…\n\n\n\n# left_join\nleft_join(data1, data2, by = c(\"ticker\", \"year\"))\n\n# A tibble: 6,969 × 25\n   companyname        stateincorp ticker  year   sic totalassets costofgoodssold\n   &lt;chr&gt;              &lt;chr&gt;       &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;           &lt;dbl&gt;\n 1 AMERICAN AIRLINES… DE          AAL     2008  4512       25175           20232\n 2 AMERICAN AIRLINES… DE          AAL     2009  4512       25438           16935\n 3 AMERICAN AIRLINES… DE          AAL     2010  4512       25088           18138\n 4 AMERICAN AIRLINES… DE          AAL     2011  4512       23848           20420\n 5 AMERICAN AIRLINES… DE          AAL     2012  4512       23510           20529\n 6 AMERICAN AIRLINES… DE          AAL     2013  4512       42278           19084\n 7 AMERICAN AIRLINES… DE          AAL     2014  4512       43771           29511\n 8 AMERICAN AIRLINES… DE          AAL     2015  4512       48415           25416\n 9 AMERICAN AIRLINES… DE          AAL     2016  4512       51274           25695\n10 AMERICAN AIRLINES… DE          AAL     2017  4512       51396           28262\n# ℹ 6,959 more rows\n# ℹ 18 more variables: netincome &lt;dbl&gt;, sale &lt;dbl&gt;, advertising &lt;dbl&gt;,\n#   sellingadmin &lt;dbl&gt;, mktvalue &lt;dbl&gt;, commonequity &lt;dbl&gt;,\n#   totalliability &lt;dbl&gt;, cik_code &lt;dbl&gt;, auditor &lt;chr&gt;,\n#   INTERNALCONTROL_EFFECTIVE &lt;chr&gt;, year_ended_date &lt;date&gt;,\n#   financials_date &lt;date&gt;, fiscal_year &lt;dbl&gt;, signature_date &lt;date&gt;,\n#   NUMBEROFCONTROLWEAKNESS &lt;dbl&gt;, audit_fees &lt;dbl&gt;, non_audit_fees &lt;dbl&gt;, …\n\n\n\n# left_join\nleft_join(data1 |&gt; distinct(ticker, year, .keep_all = TRUE), \n          data2 |&gt; distinct(ticker, year, .keep_all = TRUE), \n          by = c(\"ticker\", \"year\")\n          )\n\n# A tibble: 6,910 × 25\n   companyname        stateincorp ticker  year   sic totalassets costofgoodssold\n   &lt;chr&gt;              &lt;chr&gt;       &lt;chr&gt;  &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;           &lt;dbl&gt;\n 1 AMERICAN AIRLINES… DE          AAL     2008  4512       25175           20232\n 2 AMERICAN AIRLINES… DE          AAL     2009  4512       25438           16935\n 3 AMERICAN AIRLINES… DE          AAL     2010  4512       25088           18138\n 4 AMERICAN AIRLINES… DE          AAL     2011  4512       23848           20420\n 5 AMERICAN AIRLINES… DE          AAL     2012  4512       23510           20529\n 6 AMERICAN AIRLINES… DE          AAL     2013  4512       42278           19084\n 7 AMERICAN AIRLINES… DE          AAL     2014  4512       43771           29511\n 8 AMERICAN AIRLINES… DE          AAL     2015  4512       48415           25416\n 9 AMERICAN AIRLINES… DE          AAL     2016  4512       51274           25695\n10 AMERICAN AIRLINES… DE          AAL     2017  4512       51396           28262\n# ℹ 6,900 more rows\n# ℹ 18 more variables: netincome &lt;dbl&gt;, sale &lt;dbl&gt;, advertising &lt;dbl&gt;,\n#   sellingadmin &lt;dbl&gt;, mktvalue &lt;dbl&gt;, commonequity &lt;dbl&gt;,\n#   totalliability &lt;dbl&gt;, cik_code &lt;dbl&gt;, auditor &lt;chr&gt;,\n#   INTERNALCONTROL_EFFECTIVE &lt;chr&gt;, year_ended_date &lt;date&gt;,\n#   financials_date &lt;date&gt;, fiscal_year &lt;dbl&gt;, signature_date &lt;date&gt;,\n#   NUMBEROFCONTROLWEAKNESS &lt;dbl&gt;, audit_fees &lt;dbl&gt;, non_audit_fees &lt;dbl&gt;, …\n\n\n\n\n\ndataset1 = pd.read_csv(\"https://raw.githubusercontent.com/msharifbd/DATA/refs/heads/main/DATA.csv\")\ndataset2 = pd.read_csv(\"https://github.com/msharifbd/DATA/raw/refs/heads/main/DATA2.csv\",encoding=\"latin-1\")\n\n\npd.merge(dataset1, dataset2, on=['ticker', 'year'], how='left')\n\n                      companyname stateincorp  ... non_audit_fees  big4\n0     AMERICAN AIRLINES GROUP INC          DE  ...       990000.0   1.0\n1     AMERICAN AIRLINES GROUP INC          DE  ...      1446000.0   1.0\n2     AMERICAN AIRLINES GROUP INC          DE  ...      1455000.0   1.0\n3     AMERICAN AIRLINES GROUP INC          DE  ...      2645000.0   1.0\n4     AMERICAN AIRLINES GROUP INC          DE  ...      1989000.0   1.0\n...                           ...         ...  ...            ...   ...\n6964         INFOSONICS CORP -OLD          MD  ...            NaN   NaN\n6965         INFOSONICS CORP -OLD          MD  ...            NaN   NaN\n6966         INFOSONICS CORP -OLD          MD  ...            NaN   NaN\n6967         INFOSONICS CORP -OLD          MD  ...            NaN   NaN\n6968         INFOSONICS CORP -OLD          MD  ...            NaN   NaN\n\n[6969 rows x 25 columns]\n\n\n\ndataset1_drop = dataset1.drop_duplicates(subset=['ticker', 'year'], ignore_index = True)\ndataset2_drop = dataset2.drop_duplicates(subset=['ticker', 'year'], ignore_index = True)\npd.merge(dataset1_drop, dataset2_drop, on=['ticker', 'year'], how='left')\n\n                      companyname stateincorp  ... non_audit_fees  big4\n0     AMERICAN AIRLINES GROUP INC          DE  ...       990000.0   1.0\n1     AMERICAN AIRLINES GROUP INC          DE  ...      1446000.0   1.0\n2     AMERICAN AIRLINES GROUP INC          DE  ...      1455000.0   1.0\n3     AMERICAN AIRLINES GROUP INC          DE  ...      2645000.0   1.0\n4     AMERICAN AIRLINES GROUP INC          DE  ...      1989000.0   1.0\n...                           ...         ...  ...            ...   ...\n6905         INFOSONICS CORP -OLD          MD  ...            NaN   NaN\n6906         INFOSONICS CORP -OLD          MD  ...            NaN   NaN\n6907         INFOSONICS CORP -OLD          MD  ...            NaN   NaN\n6908         INFOSONICS CORP -OLD          MD  ...            NaN   NaN\n6909         INFOSONICS CORP -OLD          MD  ...            NaN   NaN\n\n[6910 rows x 25 columns]\n\n\n\ndf1 = pd.DataFrame({'id': [1, 2, 3], 'value': ['A', 'B', 'C']})\ndf2 = pd.DataFrame({'id': [2, 3, 4], 'other_value': ['X', 'Y', 'Z']})\n\n# Left join\nleft_join = pd.merge(df1, df2, on='id', how='left')\n\n# Inner join\ninner_join = pd.merge(df1, df2, on='id')\n\n# Semi join\nsemi_join = df1[df1['id'].isin(df2['id'])]\n\n# Anti join\nanti_join = df1[~df1['id'].isin(df2['id'])]",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Exploratory Data Analysis (EDA)</span>"
    ]
  },
  {
    "objectID": "eda.html#conclusions",
    "href": "eda.html#conclusions",
    "title": "3  Exploratory Data Analysis (EDA)",
    "section": "3.12 Conclusions",
    "text": "3.12 Conclusions\n\n\n\n\nWickham, Hadley, Mine Çetinkaya-Rundel, and Garrett Grolemund. 2023. R for Data Science. \" O’Reilly Media, Inc.\". https://r4ds.hadley.nz/.",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Exploratory Data Analysis (EDA)</span>"
    ]
  },
  {
    "objectID": "eda.html#footnotes",
    "href": "eda.html#footnotes",
    "title": "3  Exploratory Data Analysis (EDA)",
    "section": "",
    "text": "You can also use British spelling - summarise ()↩︎\nIndexing involves obtaining individual elements.↩︎\nIn database context, it is “merging”, but commonly it is called “joining”.↩︎",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Exploratory Data Analysis (EDA)</span>"
    ]
  },
  {
    "objectID": "visualization.html",
    "href": "visualization.html",
    "title": "4  Data Visualization",
    "section": "",
    "text": "Learning Objectives of the Chapter",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "visualization.html#what-is-visualization",
    "href": "visualization.html#what-is-visualization",
    "title": "4  Data Visualization",
    "section": "4.1 What is Visualization?",
    "text": "4.1 What is Visualization?\n\n     To learn more about different kinds of visualization in R, you should visit - https://r-graph-gallery.com/ and https://www.kaggle.com/code/ruchiraperera/seaborn-vs-plotly-express.",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "visualization.html#importance-of-visualization",
    "href": "visualization.html#importance-of-visualization",
    "title": "4  Data Visualization",
    "section": "4.2 Importance of Visualization",
    "text": "4.2 Importance of Visualization",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "visualization.html#visualization-packages-in-r-and-python",
    "href": "visualization.html#visualization-packages-in-r-and-python",
    "title": "4  Data Visualization",
    "section": "4.3 Visualization Packages in R and Python",
    "text": "4.3 Visualization Packages in R and Python\n\nRPython\n\n\n\n     ggplot2 is a powerful package for visualization in R. In addition, some other packages enhance the functionalities of ggplot2. These packages include - gganimate, ggthemes, ggpubr, ggridges, ggmap, ggrepel, ggextra, ggpattern, ggcorrplot and so on.\n\n\n# Loading tidyverse package\nlibrary(tidyverse)\n# Loading dataset \ntips = read_csv(\n    'https://raw.githubusercontent.com/mwaskom/seaborn-data/master/tips.csv'\n)\n\n\n\n\n     In Python, matplotlib and seaborn are two of the powerful packages for visualization. Additionally, plotly, plotnine, altair, and bokeh are some other python packages that enhances visualization in python.\n\n\n# Loading Necessary Python Packages \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\n\n# ggplot style \nplt.style.use('ggplot')\n# Loading dataset\ntips = sns.load_dataset('tips')",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "visualization.html#ggplot---grammar-of-graphics",
    "href": "visualization.html#ggplot---grammar-of-graphics",
    "title": "4  Data Visualization",
    "section": "4.4 ggplot - Grammar of Graphics",
    "text": "4.4 ggplot - Grammar of Graphics\n\n     In ggplot, a plot consists of at least four elements -\n\nData - the data frame\nAesthetic Mappings - aesthetic mappings map variable from the data frame to different kinds of aesthetics such as x coordinate, y coordinate, color, shape, size and so on.\nCoordinate System - the positioning of points\nGeom - geoms are geometirc objects such as points or lines.\n\n     You can also use cheatsheet of ggplot to know more about the ggplot. Another good source to learn more about visualization in R is The R Graph Library. Similarly, for Python, you can use The Python Graph Library.",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "visualization.html#types-of-visualization",
    "href": "visualization.html#types-of-visualization",
    "title": "4  Data Visualization",
    "section": "4.5 Types of Visualization",
    "text": "4.5 Types of Visualization\n\n4.5.1 Bar Diagram (Bar Plot)\n\n4.5.1.1 One Categorical Variable\n\nRPython\n\n\n\ntips |&gt; \n    count (sex) |&gt;\n    ggplot(mapping = aes(x = sex, y = n))+\n    geom_bar(stat = 'identity', width = 0.5, fill = \"orangered3\") + \n    labs(x = 'Sex', y = 'Total Observations')\n\n\n\n\nBar Plot of Gender (geom_bar)\n\n\n\n\n      Either of the the following code will also produce the same visualization.\n\ntips |&gt; \n    ggplot(mapping = aes(x = sex))+\n    geom_bar(width = 0.5, fill = \"maroon\") + \n    labs(x = 'Sex', y = 'Total Observations')\n\n\ntips |&gt; \n    ggplot(mapping = aes(x = sex))+\n    stat_count(width = 0.5, fill = \"maroon\") + \n    labs(x = 'Sex', y = 'Total Observations')\n\n\n\n\nsns.countplot(data = tips, x = \"sex\", width=0.5)\nplt.xlabel('Sex')\nplt.ylabel('Total Observations')\n\n\n\n\nBar Plot of Gender (sns.countplot)\n\n\n\n\n\n\n\n\n\n4.5.1.2 One Categorical Variable and One Continuous Variable\n\n     Barplot can also be used for two variables - both discrete (categorical) variables or one discrete (categorical) and one continuous variable. Below is bar plot for one discrete (categorical) and one continuous variable.\n\n\nRPython\n\n\n\ntips |&gt; \n    group_by(sex) |&gt;\n    summarize(total_bill = mean(total_bill)) |&gt;\n    ggplot(aes(x = sex, y = total_bill)) + \n    geom_col(width =0.6, fill = \"pink\") + \n    labs(x = \"Sex\", y = \"Total Bill\") + \n    geom_text(aes(label = round(total_bill,2)), vjust = -0.2)\n\n\n\n\n\n\n\n\n     The following code will produce the same results.\n\ntips |&gt; \n    ggplot(mapping = aes(x = sex, y = total_bill))+\n    geom_bar(stat = 'summary', fun = \"mean\", position = \"dodge\",\n    width = 0.60, fill = \"pink\") + \n    labs(x = \"Sex\", y = \"Total Bill\")\n\n\n\n\n\n\n\n\n\n\n\nsns.barplot(data = tips, x = \"sex\", y = \"total_bill\",\n            width= 0.5, \n            errorbar= None)\nplt.xlabel('Sex')\nplt.ylabel('Total Bill')\n\n\n\n\nBar Plot of Gender (sns.barplot)\n\n\n\n\n     The following code will add text value on the bars in barplot.\n\nax = sns.barplot(data = tips, x = \"sex\", y = \"total_bill\",\n            width= 0.5, \n            errorbar= None)\n\nfor i in ax.containers:\n    ax.bar_label(i,)\n\nplt.xlabel('Sex')\nplt.ylabel('Total Bill')\n\n\n\n\n\n\n4.5.1.3 Two Categorical Variables\n     Below is a bar plot for both discrete (categorical) variables.\n\nRPython\n\n\n\ntips |&gt; \n    count (sex, day) |&gt;\n    ggplot(mapping = aes(x = sex, y = n, fill = day))+\n    geom_bar(stat = 'identity', position = \"dodge\") + \n    labs(x = \"Sex\", y = \"Total Observations\")\n\n\n\n\nBar Plot of Gender (geom_bar - unstacking bar)\n\n\n\n\n     The following code will also produce the same visualization.\n\ntips |&gt; \n    #count (sex, day) |&gt;\n    ggplot(mapping = aes(x = sex, fill = day))+\n    geom_bar(stat = 'count', position = \"dodge\") + \n    labs(x = \"Sex\", y = \"Total Observations\"\n         ,fill = \"Day\"\n    )\n\n\n\n\n\n\n\n\n\ntips |&gt; \n    count (sex, day) |&gt;\n    ggplot(mapping = aes(x = sex, y = n, fill = day))+\n    geom_bar(stat = 'identity', position = \"stack\") + # position = \"fill\"\n    labs(x = \"Sex\", y = \"Total Observations\")\n\n\n\n\n\n\n\n\n     The following code will also produce the same visualization.\n\ntips |&gt; \n    #count (sex, day) |&gt;\n    ggplot(mapping = aes(x = sex, fill = day))+\n    geom_bar(stat = 'count', position = \"stack\") + # position = \"fill\"\n    labs(x = \"Sex\", y = \"Total Observations\"\n         ,fill = \"Day\"\n    )\n\n\n\n\n\n\n\n\n\n\n\nsns.countplot(data = tips, x = \"sex\", hue = \"day\")\nplt.xlabel('Sex')\nplt.ylabel('Total Observations')\n\n\n\n\nBar Plot of Gender (sns.countplot - unstacking bar)\n\n\n\n\n     Stacked barchart cannot be created using seaborn. So, we use alternatives -\n\ntips[['sex', 'day']].value_counts().reset_index() \\\n    .pivot(index = \"sex\", columns = \"day\", values = 'count') \\\n    .plot(kind = \"bar\", stacked = True)\nplt.xticks(rotation = 360)\n\n(array([0, 1]), [Text(0, 0, 'Male'), Text(1, 0, 'Female')])\n\nplt.xlabel(\"Sex\")\nplt.ylabel(\"Total Observations\")\nplt.legend(loc = \"upper right\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.5.2 Histogram\n\n4.5.2.1 One Continuous Variable\n\nRPython\n\n\n\ntips |&gt;\n    ggplot(aes(x = total_bill))+\n    geom_histogram(binwidth = 2.25, fill = \"orangered3\") + \n    labs(x = \"Total Bill\", y = \"Count\") \n\n\n\n\n\n\n\n\n     The following code will generate the same results with a little modification -\n\ntips |&gt;\n    ggplot(aes(x = total_bill))+\n    geom_histogram(binwidth = 2.25, fill = \"orangered3\", col = \"white\") + \n    labs(x = \"Total Bill\", y = \"Count\")\n\n\n\n\nsns.histplot(data = tips, x = \"total_bill\", binwidth=2.25)\nplt.xlabel(\"Total Bill\")\nplt.ylabel(\"Count\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.5.2.2 One Continuous and One Categorical Variable\n\nRPython\n\n\n\ntips |&gt;\n    ggplot(aes(x = total_bill, fill = sex))+\n    geom_histogram(binwidth = 2.25)+\n    labs(x = \"Total Bill\")\n\n\n\n\n\n\n\n\n     The following code will generate the same results -\n\ntips |&gt;\n    ggplot(aes(x = total_bill, color = sex))+\n    geom_histogram(binwidth = 2.25)\n\n\n\n\nsns.histplot(data = tips, x = \"total_bill\", hue = \"sex\", binwidth=2.25)\nplt.xlabel(\"Total Bill\")\nplt.ylabel(\"Count\")\n\n\n\n\n\n\n\n\n\nsns.FacetGrid(data=tips, col=\"sex\") \\\n    .map(sns.histplot, \"total_bill\", binwidth = 2.25)\n\n\n\n\n\n\n\n4.5.3 Density Plot\n\n4.5.3.1 One Continuous Variable\n\nRPython\n\n\n\ntips |&gt;\n    ggplot(aes(x = total_bill))+\n    geom_density( size = 1, color = \"orangered3\"\n        #adjust = 0.2\n    ) + \n    labs(x = \"Total Bill\", y = \"Density\")\n\n\n\n\n\n\n\n\n\n\n\nsns.kdeplot(data = tips, x = \"total_bill\"\n            #,bw_adjust = 0.20\n            )\nplt.xlabel(\"Total Bill\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.5.3.2 Two Continuous Variables\n\nRPython\n\n\n\ntips |&gt;\n    select(1:2) |&gt;\n    pivot_longer(cols = everything(), names_to = \"types\", values_to = \"values\") |&gt;\n    ggplot(aes(x = values, col = types))+\n    geom_density(size = 1)\n\n\n\n\n\n\n\n\n\n\n\nsns.kdeplot(data = tips[['total_bill', 'tip']])\nplt.xlabel(\"Total Bill\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.5.3.3 One Continuous Variable and One Categorical Variable\n\nRPython\n\n\n\ntips |&gt;\n    ggplot(aes(x = total_bill, fill = sex))+\n    geom_density(\n        #adjust = 0.2\n    )+ \n    labs(x = \"Total Bill\", y = \"Density\")\n\n\n\n\n\n\n\n\n\ntips |&gt;\n    ggplot(aes(x = total_bill, color = sex))+\n    geom_density(size = 1\n        #adjust = 0.2\n    )+ \n    labs(x = \"Total Bill\", y = \"Density\")\n\n\n\n\n\n\n\n\n\n\n\nsns.kdeplot(data = tips, x = \"total_bill\", hue = \"sex\")\nplt.xlabel(\"Total Bill\")\n\n\n\n\n\n\n\n\n\nsns.kdeplot(data = tips, x = \"total_bill\", hue = \"sex\", multiple = \"stack\")\nplt.xlabel(\"Total Bill\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.5.4 Point Plot\n\n4.5.4.1 One Categorical and One Continuous Variable\n\nRPython\n\n\n\ntips |&gt; \n    ggplot(aes(x = sex, y = total_bill, group = 1)) + \n    stat_summary(aes(sex, total_bill), geom = \"point\", fun.y = mean, size = 2, col = \"red\")+\n    stat_summary(aes(sex, total_bill), geom = \"line\", fun.y = mean, size = 1.5, col = \"red\",size = 2.1) + \n    labs(x = \"Sex\", y = \"Total Bill\")\n\n\n\n\nLine Plot of Gender (geom_line - mean)\n\n\n\n\n     The following code will also produce the same visualization.\n\ntips |&gt; \n    group_by(sex) |&gt;\n    summarize(total_bill = mean(total_bill)) |&gt;\n    ggplot(aes(x = sex, y = total_bill, group = 1)) + \n    geom_point(col = \"red\", size = 2)+\n    geom_line(col = \"red\", size = 2.1) + \n    labs(x = \"Sex\", y = \"Total Bill\")\n\n\n\n\n\n\n\n\n\n\n\nsns.pointplot(data = tips, x = \"sex\", y = \"total_bill\", errorbar=None)\nplt.xlabel('Sex')\nplt.ylabel(\"Total Bill\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.5.4.2 Two Categorical Variables and One Continuous Variable\n\nRPython\n\n\n\ntips |&gt;\n    ggplot(aes(x = sex, y = total_bill, group = smoker, color = smoker)) + \n    stat_summary(aes(x = sex, y = total_bill), geom = \"point\", fun.y = mean) + \n    stat_summary(aes(x = sex, y = total_bill), geom = \"line\", fun.y = mean, size = 1.1) + \n    labs(x = \"Sex\", y = \"Total Bill\" #, color = \"Smoker\"\n    )\n\n\n\n\n\n\n\n\n     The following code will also produce the same visualization.\n\ntips |&gt;\n    group_by(sex, smoker) |&gt;\n    summarize( total_bill = mean(total_bill)) |&gt;\n    ggplot(aes(x = sex, y = total_bill, group = smoker , color = smoker)) + \n    geom_point()+\n    geom_line(size = 1.1)+\n    labs(x = \"Sex\", y = \"Total Bill\")\n\n\n\n\n\n\n\n\n\n\n\nsns.pointplot(data = tips, x = \"sex\", y = \"total_bill\", \n              hue = \"smoker\", errorbar= None)\nplt.xlabel(\"Sex\")\nplt.ylabel(\"Total Bill\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.5.5 Box Plot\n\nRPython\n\n\n\ntips |&gt;\n    ggplot(aes(x = sex, y = total_bill))+\n    geom_boxplot(fill = \"pink\") + \n    labs (x = \"Sex\", y = \"Total Bill\")\n\n\n\n\n\n\n\n\n\ntips |&gt;\n    ggplot(aes(x = sex, y = total_bill))+\n    geom_boxplot(fill = \"pink\") + \n    labs (x = \"Sex\", y = \"Total Bill\") + \n    facet_wrap(~smoker)\n\n\n\n\n\n\n\ntips |&gt;\n    ggplot(aes(x = sex, y = total_bill))+\n    geom_boxplot(fill = \"pink\") + \n    labs (x = \"Sex\", y = \"Total Bill\") + \n    facet_grid(time~smoker)\n\n\n\n\n\n\n\n\n\n\n\nsns.boxplot(data = tips, x = \"sex\", y = \"total_bill\", color = \"pink\")\nplt.xlabel(\"Sex\")\nplt.ylabel(\"Total Bill\")\n\n\n\n\n\n\n\n\n\nsns.catplot(data = tips, x = \"sex\", y = \"total_bill\", \n            color = \"pink\", kind = \"box\", row = \"smoker\"\n           )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nsns.catplot(data = tips, x = \"sex\", y = \"total_bill\", \n            color = \"pink\", kind = \"box\", row = \"smoker\"\n            ,col = \"time\"\n           )\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.5.6 Scatter Plot\n\nRPython\n\n\n\ntips |&gt;\n    ggplot(aes(x = total_bill, y = tip))+\n    geom_point(col = \"blue\")+\n    labs(x = \"Total Bill\", y = \"Tip\")\n\n\n\n\n\n\n\n\n\n\n\nsns.scatterplot(data = tips, x = \"total_bill\", y = \"tip\")\nplt.xlabel(\"Total Bill\")\nplt.ylabel(\"Tip\")\n\n\n\n\n\n\n\n\n\n\n\n\n\n4.5.7 Regression Plot\n\nRPython\n\n\n\ntips |&gt;\n    ggplot(aes(x = total_bill, y = tip))+\n    geom_point(col = \"blue\")+\n    geom_smooth(method = \"lm\", col = \"orange\") + \n    labs(x = \"Total Bill\", y = \"Tip\")\n\n\n\n\n\n\n\n\n\ntips |&gt;\n    ggplot(aes(x = total_bill, y = tip, col = sex))+\n    geom_point(col = \"blue\")+\n    geom_smooth(method = \"lm\") + \n    labs(x = \"Total Bill\", y = \"Tip\")\n\n\n\n\n\n\n\n\n\n\n\nsns.lmplot(data = tips, x = \"total_bill\", y = \"tip\")\n\n\n\n\n\n\n\nplt.xlabel(\"Total Bill\")\nplt.ylabel(\"Tip\")\n\n\n\n\n\n\n\n\n\nsns.regplot(data = tips, x = \"total_bill\", y = \"tip\")\nplt.xlabel(\"Total Bill\")\nplt.ylabel(\"Tip\")\n\n\n\n\n\n\n\n\n\nsns.lmplot(data = tips, x = \"total_bill\", y = \"tip\", hue = \"sex\")\n\n\n\n\n\n\n\nplt.xlabel(\"Total Bill\")\nplt.ylabel(\"Tip\")",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "visualization.html#exercises-01",
    "href": "visualization.html#exercises-01",
    "title": "4  Data Visualization",
    "section": "4.6 Exercises # 01",
    "text": "4.6 Exercises # 01\n\nDownload student data from the url and create a pointplot (lineplot) of students average math score (math.grade) of gender (gender). Please note that the variable gender includes a label called other in addition to M and F; you should filter out obsevations of the label other before you create visualization.\nFrom the dataset in above (question 1), compare, using pointplot (lineplot), the average math (math.grade) and science score (sciences.grade) of different students based on gender (gender). You might need to use pivot_longer function to reshape the data frame before visualizing the relation.",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "visualization.html#interactive-visualization",
    "href": "visualization.html#interactive-visualization",
    "title": "4  Data Visualization",
    "section": "4.7 Interactive Visualization",
    "text": "4.7 Interactive Visualization\n\n     Interactive Visualization involves graphical presentation of data that permits users to engage with the visual elements directly. Unlike static visulization, interactive visualization allows users to manipulate data, explore different aspects, and customize the visualization in real time. The primary objective of interactive visualization is to make data exploration more intuititve and dynamic. The benefits of interactive visualzation include - enhaned engagement, deeper insights, customization, and exploration and discovery.\n\n\nRPythonPlotnine\n\n\n\nlibrary(plotly)\n\n\np = ggplot(data = tips, aes(x = sex)) + \n    geom_bar(width = 0.5, fill = \"orangered3\") + \n    labs(x = \"Gender\", y = \"Total Observations\")\n\nggplotly(p)\n\n\n\n\n\n\np2 = tips |&gt;\n    ggplot(aes(x = time, y = total_bill, group = smoker, color = smoker))+\n    stat_summary(aes(x = time, y = total_bill), geom = \"point\", fun.y = mean) + \n    stat_summary(aes(x = time, y = total_bill), geom = \"line\", fun.y = mean, size = 1.1) + \n    labs (x = \"Time\", y = \"Total Bill\")\n\nggplotly(p2)\n\n\n\n\n\n\n\n\nimport plotly.express as px\n\n\nfig = px.histogram(tips, x = \"sex\") \\\n    .update_traces(marker_color = \"orangered\") \\\n    .update_xaxes(title = \"Sex\") \\\n    .update_yaxes(title = \"Count\")\nfig.show()\n\n                        \n                                            \n\n\n\npx.histogram(tips, x = \"sex\", y = \"total_bill\",histfunc='avg') \\\n    .update_traces(marker_color = \"orangered\") \\\n    .update_xaxes(title = \"Sex\") \\\n    .update_yaxes(title = \"Average Total Bill\") \\\n    .show()\n\n                        \n                                            \n\n\n\npx.histogram(tips, x=\"total_bill\",histnorm='probability density',\n             width=600, height=400) \\\n                .update_xaxes(title = \"Total Bill\") \\\n                .update_yaxes(title =\"Density\")\n\n                        \n                                            \n\n\n\n\n\n#import plotnine as p9\nfrom plotnine import *\nimport plotly.tools as tls\n\ndf = tips.groupby([\"sex\"])[\"total_bill\"].agg('mean').reset_index()\n\n\n(\n    ggplot(df, aes(x = \"sex\", y = \"total_bill\", group = 1)) + \n    geom_point(color = \"blue\")+\n    geom_line(color = \"orange\", size = 1.1) + \n    labs(x = \"Sex\", y = \"Average Total Bill\")\n)\n\n&lt;Figure Size: (640 x 480)&gt;\n\n\n\n\n\n\n\n\nplotly_fig = (\n    ggplot(df, aes(x = \"sex\", y = \"total_bill\", group = 1)) + \n    geom_point(color = \"blue\")+\n    geom_line(color = \"orange\", size = 1.1)\n)\ntls.mpl_to_plotly(plotly_fig.draw()).show()\n\n                        \n                                            \n\n\n\ndf2 = tips.groupby([\"sex\", \"smoker\"])[\"total_bill\"] \\\n    .agg('mean') \\\n    .round(2) \\\n    .reset_index()\n\n(\n    ggplot(df2, aes(x = \"sex\", y = \"total_bill\",  group = \"smoker\", color = \"smoker\")) + \n    geom_point()+\n    geom_line(size = 1.1) + \n    labs(x = \"Sex\", y = \"Average Total Bill\")\n)\n\n&lt;Figure Size: (640 x 480)&gt;",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "visualization.html#exercises-02",
    "href": "visualization.html#exercises-02",
    "title": "4  Data Visualization",
    "section": "4.8 Exercises # 02",
    "text": "4.8 Exercises # 02",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Data Visualization</span>"
    ]
  },
  {
    "objectID": "dashboard.html",
    "href": "dashboard.html",
    "title": "5  Dashboard for Visualization",
    "section": "",
    "text": "Learning Objectives of the Chapter",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dashboard for Visualization</span>"
    ]
  },
  {
    "objectID": "dashboard.html#what-is-dashboard",
    "href": "dashboard.html#what-is-dashboard",
    "title": "5  Dashboard for Visualization",
    "section": "5.1 What is Dashboard?",
    "text": "5.1 What is Dashboard?\n\n     A dashboard for visualization is a user interface that displays a collection of visual data representations, such as charts, graphs, tables, and metrics, to provide users with an interactive and comprehensive overview of key information. Dashboards are commonly used in business, data science, finance, healthcare, and other fields to monitor performance, track metrics, and explore data trends in real time.\n     The main goal of a dashboard is to present complex data in an easy-to-understand format, enabling users to quickly grasp insights and make data-driven decisions. Dashboards often combine multiple visual elements into a single screen or page, allowing users to view different aspects of the data simultaneously. They typically include interactive features like filters, drill-downs, and tooltips, which allow users to interact with the data and explore deeper insights without needing to understand the underlying data structures. Some benefits of dashboards are -\n\nData Aggregation: Dashboards bring together data from various sources, providing a unified view of different datasets.\nVisualization Elements: They use visual elements such as bar charts, line graphs, pie charts, heatmaps, and more to represent data in a visually appealing and informative way.\nInteractivity: Users can interact with the visual elements, applying filters, adjusting time frames, or drilling down into specific data points to gain more detailed insights.\nReal-Time Data: Dashboards can display real-time data, updating visualizations dynamically to reflect the latest information, which is especially useful for monitoring live systems or business performance.\nCustomization: Dashboards are highly customizable, allowing users to tailor the layout, visualizations, and data to meet their specific needs.\n\n     Dashboards for visualization are widely used for performance monitoring (e.g., tracking KPIs), data exploration (e.g., identifying trends), and decision-making (e.g., comparing metrics). They make data analysis more accessible to a wider audience by simplifying the complexity of raw data into clear and actionable insights.",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dashboard for Visualization</span>"
    ]
  },
  {
    "objectID": "dashboard.html#importance-of-dashboard",
    "href": "dashboard.html#importance-of-dashboard",
    "title": "5  Dashboard for Visualization",
    "section": "5.2 Importance of Dashboard",
    "text": "5.2 Importance of Dashboard",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dashboard for Visualization</span>"
    ]
  },
  {
    "objectID": "dashboard.html#interactive-dashboard",
    "href": "dashboard.html#interactive-dashboard",
    "title": "5  Dashboard for Visualization",
    "section": "5.3 Interactive Dashboard",
    "text": "5.3 Interactive Dashboard\n     For interactive visualization, see Figure 5.3.",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dashboard for Visualization</span>"
    ]
  },
  {
    "objectID": "dashboard.html#quarto---r-and-python-dashboard",
    "href": "dashboard.html#quarto---r-and-python-dashboard",
    "title": "5  Dashboard for Visualization",
    "section": "5.4 Quarto - R and Python Dashboard",
    "text": "5.4 Quarto - R and Python Dashboard\n\n     Quarto Dashboard is a powerful and flexible open-source tool to create interactive dashboard in R or Python. Quarto dashboards are easy to create and support a wide variety of visualization and interactive components1. More about quarto dashboard can be learned from Quarto Dashboard Website. To learn more about interactivity on quarto dashboard using Shiny, please visit webpages for R and Python. However, it is recommended to use Python for quarto dashboard if you want to include interactive applications on your dashboard.\n     There are several components of quarto dashboard:\n\nNavigation Bar - Top page bar with icon, title of the dashboard, name of author and links to sub-pages\nPages, Rows, Columns, and Tabsets - Using markdown headings (#) - pages, rows and columns are defined. Tabsets are used to further divide the content within a row or column\nCards, Sidebar, and Toolbars - Cards are containers for text, images, charts, and interactive elements and useful for organizing information into distinct sections within a dashboard. Typically, the contents of cards map to cells in the dashboard. Sidebar is another layout component of quarto dashboard, which contain navigation menus, filters, and controls that allow users to adjust or explore the data presented in the main content. Toolbars ….\n\n     The first step to create a quarto dashboard is to structure YAML in .qmd file. A quarto dashboard YAML look like -\n\n\n\n\n\n\nFigure 5.1: Quarto Dashboard YAML\n\n\n\n     In quarto dashboard, each level 1 header (#) introduces a new page, each level 2 header (##) introduces a new row within the given page, and each code chunk within a given row introduces a new column.\n\n\n\n\n\n\nFigure 5.2: Quarto Dashboard Structure\n\n\n\n     Some other attributes (Table 5.1) that can be added to the quarto dashboard’s rows or columns include -\n\n\n\nTable 5.1: Some Additional Attributes\n\n\n\n\n\n\n\n\n\nAttribute\nExplanation\n\n\n\n\n{width=} and {height=}\nSet the size of columns, rows, and boxes\n\n\n{orientation=}\nsets the dashboard layout to either rows or columns. This is a global option set in the YAML. However, if your dashboard has multiple pages and you want to specify the orientation for each page, remove orientation: from the YAML and use this attribute instead\n\n\n{.tabset}\ndivide columns, rows, or charts into tabs\n\n\n{.sidebar}\ntypically creates a sidebar on the page\n\n\n{.hidden}\nexcludes a specific page from the navigation bar",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dashboard for Visualization</span>"
    ]
  },
  {
    "objectID": "dashboard.html#vizro---python-dashboard",
    "href": "dashboard.html#vizro---python-dashboard",
    "title": "5  Dashboard for Visualization",
    "section": "5.5 Vizro - Python Dashboard",
    "text": "5.5 Vizro - Python Dashboard\n\n     Built on top of Dash and Plottly, Vizro is a powerful python module to create a dashboard. A vizro dashboard consists of several objects. The first object is Page. Each page contains several other sub-objects such as Comonents, which can include Graphs and Tables, Filters, which can be sliders, dropdown boxes and other buttons, and optional Actions. To learn more about Vizro, we can explore Vizro document website and developer website. The key benefits of Vizro include:\n\nLow-code and Configuration - Vizro only needs a few lines of code code, thus replacing thousand lines of codes and saving valuable time\nIn-built Best Practices - Vizro already incorporates standards for visual design and software development.\nSelf-service Visualization - Vizro readily assemble dashboards without advanced design or coding experience\nOptional High-code Extensions - Vizro enables limitless customization for advanced users with complex needs\nModularity - Vizro leverage components that are simple to swap, reuse, maintain, share and scale\nFlexibilit and Scalability - Vizro enables data science ready and to develop python based data visualization applications\n\n\n\n# Dashboard Creation \nfrom vizro import Vizro\nimport vizro.models as vm\nimport vizro.plotly.express as px\n\n# Data Visualization \nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\n\n\n# loading dataset \nimport palmerpenguins\ndf = palmerpenguins.load_penguins()\n\n\n5.5.1 Standalone Page on Vizro Dashboard (Example # 01)\n\nVizro._reset()\n\nfirst_page = vm.Page(\n    title= \" \", \n    components= [\n        vm.Graph(\n            id = 'boxplot', \n            figure = px.box (df, x = 'species', y = 'bill_length_mm', \n            color = 'species', \n            labels={'species':'Species', 'bill_length_mm':'Bill Length (mm)'})\n        ),\n    ],\n)\n\ndashboard = vm.Dashboard(pages=[first_page])\nVizro().build(dashboard).run()\n\n\n\n\n        \n        \n\n\nFigure 5.3: A Sample of Vizro Dashboard\n\n\n\n\n\n\n5.5.2 Standalone Page on Vizro Dashboard (Example # 02)\n\n# loading dataset \ndf = px.data.gapminder()\ngapminder_data = (\n        df.groupby(by=[\"continent\", \"year\"]).\n            agg({\"lifeExp\": \"mean\", \"pop\": \"sum\", \"gdpPercap\": \"mean\"}).reset_index()\n    )\n\n\nVizro._reset()\nsecond_page = vm.Page(\n    title=\"First Page\",\n    components=[\n        vm.Card(\n            text=\"\"\"\n                # First dashboard page\n                This pages shows the inclusion of markdown text in a page and how components\n                can be structured using Layout.\n            \"\"\",\n        ),\n        vm.Graph(\n            figure=px.box(gapminder_data, x=\"continent\", y=\"lifeExp\", color=\"continent\",\n                            labels={\"lifeExp\": \"Life Expectancy\", \"continent\": \"Continent\"}),\n        ),\n        vm.Graph(\n            figure=px.line(gapminder_data, x=\"year\", y=\"gdpPercap\", color=\"continent\",\n                            labels={\"year\": \"Year\", \"continent\": \"Continent\",\n                            \"gdpPercap\":\"GDP Per Cap\"}, title=''),\n        ),\n\n    ],\n)\n\ndashboard2 = vm.Dashboard(pages=[second_page])\nVizro().build(dashboard2).run()\n\n\n\n5.5.3 Multiple Pages on Vizro Dashboard\n\nVizro._reset()\n\nthird_page = vm.Page(\n    title=\"First Page\",\n    layout=vm.Layout(grid=[[0, 0], [1, 2], [1, 2], [1, 2]]),\n    components=[\n        vm.Card(\n            text=\"\"\"\n                # First dashboard page\n                This pages shows the inclusion of markdown text in a page and how components\n                can be structured using Layout.\n            \"\"\",\n        ),\n        vm.Graph(\n            figure=px.box(gapminder_data, x=\"continent\", y=\"lifeExp\", color=\"continent\",\n                            labels={\"lifeExp\": \"Life Expectancy\", \"continent\": \"Continent\"}),\n        ),\n        vm.Graph(\n            figure=px.line(gapminder_data, x=\"year\", y=\"gdpPercap\", color=\"continent\",\n                            labels={\"year\": \"Year\", \"continent\": \"Continent\",\n                            \"gdpPercap\":\"GDP Per Cap\"}),\n            ),\n    ],\n)\n\ndashboard3 = vm.Dashboard(pages=[third_page])\nVizro().build(dashboard3).run()\n\n\nVizro._reset()\n\nsecond_page = vm.Page(\n    title=\"Second Page\",\n    components=[\n        vm.Card(\n            text=\"\"\"\n                # First dashboard page\n                This pages shows the inclusion of markdown text in a page and how components\n                can be structured using Layout.\n            \"\"\",\n        ),\n        vm.Graph(\n            figure=px.box(gapminder_data, x=\"continent\", y=\"lifeExp\", color=\"continent\",\n                            labels={\"lifeExp\": \"Life Expectancy\", \"continent\": \"Continent\"}),\n        ),\n        vm.Graph(\n            figure=px.line(gapminder_data, x=\"year\", y=\"gdpPercap\", color=\"continent\",\n                            labels={\"year\": \"Year\", \"continent\": \"Continent\",\n                            \"gdpPercap\":\"GDP Per Cap\"}, title=''),\n        ),\n\n    ],\n)\n\nthird_page = vm.Page(\n    title=\"Third Page\",\n    layout=vm.Layout(grid=[[0, 0], [1, 2], [1, 2], [1, 2]]),\n    components=[\n        vm.Card(\n            text=\"\"\"\n                # First dashboard page\n                This pages shows the inclusion of markdown text in a page and how components\n                can be structured using Layout.\n            \"\"\",\n        ),\n        vm.Graph(\n            figure=px.box(gapminder_data, x=\"continent\", y=\"lifeExp\", color=\"continent\",\n                            labels={\"lifeExp\": \"Life Expectancy\", \"continent\": \"Continent\"}),\n        ),\n        vm.Graph(\n            figure=px.line(gapminder_data, x=\"year\", y=\"gdpPercap\", color=\"continent\",\n                            labels={\"year\": \"Year\", \"continent\": \"Continent\",\n                            \"gdpPercap\":\"GDP Per Cap\"}),\n            ),\n    ],\n)\n\ndashboard4 = vm.Dashboard(pages=[second_page, third_page])\nVizro().build(dashboard4).run()",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dashboard for Visualization</span>"
    ]
  },
  {
    "objectID": "dashboard.html#conclusions",
    "href": "dashboard.html#conclusions",
    "title": "5  Dashboard for Visualization",
    "section": "5.6 Conclusions",
    "text": "5.6 Conclusions",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dashboard for Visualization</span>"
    ]
  },
  {
    "objectID": "dashboard.html#exercises",
    "href": "dashboard.html#exercises",
    "title": "5  Dashboard for Visualization",
    "section": "5.7 Exercises",
    "text": "5.7 Exercises\n\nCreate a dashboard from Adidas (Ticker:ADR) sales data (Adidas US Sales Datasets.csv).",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dashboard for Visualization</span>"
    ]
  },
  {
    "objectID": "dashboard.html#footnotes",
    "href": "dashboard.html#footnotes",
    "title": "5  Dashboard for Visualization",
    "section": "",
    "text": "Shiny widgets and functionality can be incorporated in the quarto dashboard. Therefore, quarto dashboard is a powerful tool for creating interactive visualization.↩︎",
    "crumbs": [
      "Data Exploration and Management",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Dashboard for Visualization</span>"
    ]
  }
]